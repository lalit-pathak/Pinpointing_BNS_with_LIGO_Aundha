{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "effective-roulette",
   "metadata": {},
   "source": [
    "### $\\Rightarrow$ In this notebook, we shall extract the noise from the detector with the lowest SNR recorded for the GW170817 event and use it to in estimating the PSD for LIGO India. This would a conservative choice for choosing a PSD for LIGO India (worst case scenario)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mounted-research",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "quality-medicare",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- import modules --\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pycbc import dq\n",
    "from pycbc.results import ifo_color\n",
    "from pycbc.types import FrequencySeries,TimeSeries\n",
    "\n",
    "from gwosc.datasets import event_gps\n",
    "from gwpy.timeseries import TimeSeries as gwpyTimeSeries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spanish-copyright",
   "metadata": {},
   "source": [
    "### We shall choose a noise segment which has no signal. For this we take the noise segments a few hundred seconds away from the ```trigTime``` for GW170817 event"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tested-today",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "competitive-anthony",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#-- we start from 200 secs after the trigTime of GW170817 and till 5000 secs after the start_time \n",
    "#-- in all we query for 5000 seconds of the data --\n",
    "\n",
    "trigTime = 1187008882    # secs        (to be precise it was recorded to be 1187008882.4 LIGO GPS secs)\n",
    "\n",
    "start = 200     # secs\n",
    "end = 5000      # secs\n",
    "\n",
    "start_time = trigTime + start\n",
    "end_time = start_time + end\n",
    "\n",
    "# Get times that the Hanford detector has data\n",
    "hsegs = dq.query_flag('H1', 'DATA', start_time, end_time)\n",
    "\n",
    "# Get times that the Livingston detector has data\n",
    "lsegs = dq.query_flag('L1', 'DATA', start_time, end_time)\n",
    "\n",
    "# Get times that the Livingston detector has data\n",
    "vsegs = dq.query_flag('V1', 'DATA', start_time, end_time)\n",
    "\n",
    "\n",
    "# plots \n",
    "\n",
    "plt.figure(figsize=[10,4])\n",
    "\n",
    "for seg in lsegs:\n",
    "    start, end = seg\n",
    "    plt.axvspan(start, end, color=ifo_color('L1'), ymin=0.05, ymax=0.3, label='L1')\n",
    "\n",
    "for seg in hsegs:\n",
    "    start, end = seg\n",
    "    plt.axvspan(start, end, color=ifo_color('H1'), ymin=0.4, ymax=0.7, label='H1')\n",
    "    \n",
    "for seg in vsegs:\n",
    "    start, end = seg\n",
    "    plt.axvspan(start, end, color=ifo_color('V1'), ymin=0.8, ymax=0.98)\n",
    "    \n",
    "plt.axvline(x=trigTime, ls='--', c='k')\n",
    "plt.legend()\n",
    "plt.xlabel('Time (s)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedicated-smell",
   "metadata": {},
   "source": [
    "### Note for the colors and corresponding detectors \n",
    "\n",
    "* L1 : Blue\n",
    "\n",
    "* H1 : Red\n",
    "\n",
    "* V1 : Violet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attached-insight",
   "metadata": {},
   "source": [
    "## Extracting noise from a detectors for LIGO India "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "confused-shipping",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trigTime t_c (GPS) for GW170817\n",
    "\n",
    "trigTime = event_gps(\"GW170817\")\n",
    "\n",
    "start_time = int(trigTime) + 200\n",
    "end_time = start_time + 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "veterinary-mailing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1187008882.4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "intelligent-abortion",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- fetching the data using 'gwpy'\n",
    "\n",
    "ifos = ['L1', 'H1', 'V1']\n",
    "det_strain = {}\n",
    "\n",
    "for ifo in ifos:\n",
    "    \n",
    "    det_strain[ifo] = gwpyTimeSeries.fetch_open_data(ifo, start_time, end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "virgin-rental",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Time object: scale='utc' format='gps' value=1187009082.0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "det_strain['L1'].epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "scenic-electric",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on TimeSeries in module gwpy.timeseries.timeseries object:\n",
      "\n",
      "class TimeSeries(gwpy.timeseries.core.TimeSeriesBase)\n",
      " |  TimeSeries(data, unit=None, t0=None, dt=None, sample_rate=None, times=None, channel=None, name=None, **kwargs)\n",
      " |  \n",
      " |  A time-domain data array.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  value : array-like\n",
      " |      input data array\n",
      " |  \n",
      " |  unit : `~astropy.units.Unit`, optional\n",
      " |      physical unit of these data\n",
      " |  \n",
      " |  t0 : `~gwpy.time.LIGOTimeGPS`, `float`, `str`, optional\n",
      " |      GPS epoch associated with these data,\n",
      " |      any input parsable by `~gwpy.time.to_gps` is fine\n",
      " |  \n",
      " |  dt : `float`, `~astropy.units.Quantity`, optional\n",
      " |      time between successive samples (seconds), can also be given inversely\n",
      " |      via `sample_rate`\n",
      " |  \n",
      " |  sample_rate : `float`, `~astropy.units.Quantity`, optional\n",
      " |      the rate of samples per second (Hertz), can also be given inversely\n",
      " |      via `dt`\n",
      " |  \n",
      " |  times : `array-like`\n",
      " |      the complete array of GPS times accompanying the data for this series.\n",
      " |      This argument takes precedence over `t0` and `dt` so should be given\n",
      " |      in place of these if relevant, not alongside\n",
      " |  \n",
      " |  name : `str`, optional\n",
      " |      descriptive title for this array\n",
      " |  \n",
      " |  channel : `~gwpy.detector.Channel`, `str`, optional\n",
      " |      source data stream for these data\n",
      " |  \n",
      " |  dtype : `~numpy.dtype`, optional\n",
      " |      input data type\n",
      " |  \n",
      " |  copy : `bool`, optional\n",
      " |      choose to copy the input data to new memory\n",
      " |  \n",
      " |  subok : `bool`, optional\n",
      " |      allow passing of sub-classes by the array generator\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The necessary metadata to reconstruct timing information are recorded\n",
      " |  in the `epoch` and `sample_rate` attributes. This time-stamps can be\n",
      " |  returned via the :attr:`~TimeSeries.times` property.\n",
      " |  \n",
      " |  All comparison operations performed on a `TimeSeries` will return a\n",
      " |  `~gwpy.timeseries.StateTimeSeries` - a boolean array\n",
      " |  with metadata copied from the starting `TimeSeries`.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from gwpy.timeseries import TimeSeries\n",
      " |  \n",
      " |  To create an array of random numbers, sampled at 100 Hz, in units of\n",
      " |  'metres':\n",
      " |  \n",
      " |  >>> from numpy import random\n",
      " |  >>> series = TimeSeries(random.random(1000), sample_rate=100, unit='m')\n",
      " |  \n",
      " |  which can then be simply visualised via\n",
      " |  \n",
      " |  >>> plot = series.plot()\n",
      " |  >>> plot.show()\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      TimeSeries\n",
      " |      gwpy.timeseries.core.TimeSeriesBase\n",
      " |      gwpy.types.series.Series\n",
      " |      gwpy.types.array.Array\n",
      " |      astropy.units.quantity.Quantity\n",
      " |      numpy.ndarray\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  asd(self, fftlength=None, overlap=None, window='hann', method='median', **kwargs)\n",
      " |      Calculate the ASD `FrequencySeries` of this `TimeSeries`\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fftlength : `float`\n",
      " |          number of seconds in single FFT, defaults to a single FFT\n",
      " |          covering the full duration\n",
      " |      \n",
      " |      overlap : `float`, optional\n",
      " |          number of seconds of overlap between FFTs, defaults to the\n",
      " |          recommended overlap for the given window (if given), or 0\n",
      " |      \n",
      " |      window : `str`, `numpy.ndarray`, optional\n",
      " |          window function to apply to timeseries prior to FFT,\n",
      " |          see :func:`scipy.signal.get_window` for details on acceptable\n",
      " |          formats\n",
      " |      \n",
      " |      method : `str`, optional\n",
      " |          FFT-averaging method (default: ``'median'``),\n",
      " |          see *Notes* for more details\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      asd :  `~gwpy.frequencyseries.FrequencySeries`\n",
      " |          a data series containing the ASD\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      TimeSeries.psd\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The accepted ``method`` arguments are:\n",
      " |      \n",
      " |      - ``'bartlett'`` : a mean average of non-overlapping periodograms\n",
      " |      - ``'median'`` : a median average of overlapping periodograms\n",
      " |      - ``'welch'`` : a mean average of overlapping periodograms\n",
      " |  \n",
      " |  auto_coherence(self, dt, fftlength=None, overlap=None, window='hann', **kwargs)\n",
      " |      Calculate the frequency-coherence between this `TimeSeries`\n",
      " |      and a time-shifted copy of itself.\n",
      " |      \n",
      " |      The standard :meth:`TimeSeries.coherence` is calculated between\n",
      " |      the input `TimeSeries` and a :meth:`cropped <TimeSeries.crop>`\n",
      " |      copy of itself. Since the cropped version will be shorter, the\n",
      " |      input series will be shortened to match.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dt : `float`\n",
      " |          duration (in seconds) of time-shift\n",
      " |      \n",
      " |      fftlength : `float`, optional\n",
      " |          number of seconds in single FFT, defaults to a single FFT\n",
      " |          covering the full duration\n",
      " |      \n",
      " |      overlap : `float`, optional\n",
      " |          number of seconds of overlap between FFTs, defaults to the\n",
      " |          recommended overlap for the given window (if given), or 0\n",
      " |      \n",
      " |      window : `str`, `numpy.ndarray`, optional\n",
      " |          window function to apply to timeseries prior to FFT,\n",
      " |          see :func:`scipy.signal.get_window` for details on acceptable\n",
      " |          formats\n",
      " |      \n",
      " |      **kwargs\n",
      " |          any other keyword arguments accepted by\n",
      " |          :func:`matplotlib.mlab.cohere` except ``NFFT``, ``window``,\n",
      " |          and ``noverlap`` which are superceded by the above keyword\n",
      " |          arguments\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      coherence : `~gwpy.frequencyseries.FrequencySeries`\n",
      " |          the coherence `FrequencySeries` of this `TimeSeries`\n",
      " |          with the other\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The :meth:`TimeSeries.auto_coherence` will perform best when\n",
      " |      ``dt`` is approximately ``fftlength / 2``.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      matplotlib.mlab.cohere\n",
      " |          for details of the coherence calculator\n",
      " |  \n",
      " |  average_fft(self, fftlength=None, overlap=0, window=None)\n",
      " |      Compute the averaged one-dimensional DFT of this `TimeSeries`.\n",
      " |      \n",
      " |      This method computes a number of FFTs of duration ``fftlength``\n",
      " |      and ``overlap`` (both given in seconds), and returns the mean\n",
      " |      average. This method is analogous to the Welch average method\n",
      " |      for power spectra.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fftlength : `float`\n",
      " |          number of seconds in single FFT, default, use\n",
      " |          whole `TimeSeries`\n",
      " |      \n",
      " |      overlap : `float`, optional\n",
      " |          number of seconds of overlap between FFTs, defaults to the\n",
      " |          recommended overlap for the given window (if given), or 0\n",
      " |      \n",
      " |      window : `str`, `numpy.ndarray`, optional\n",
      " |          window function to apply to timeseries prior to FFT,\n",
      " |          see :func:`scipy.signal.get_window` for details on acceptable\n",
      " |          formats\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out : complex-valued `~gwpy.frequencyseries.FrequencySeries`\n",
      " |          the transformed output, with populated frequencies array\n",
      " |          metadata\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      TimeSeries.fft\n",
      " |         The FFT method used.\n",
      " |  \n",
      " |  bandpass(self, flow, fhigh, gpass=2, gstop=30, fstop=None, type='iir', filtfilt=True, **kwargs)\n",
      " |      Filter this `TimeSeries` with a band-pass filter.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      flow : `float`\n",
      " |          lower corner frequency of pass band\n",
      " |      \n",
      " |      fhigh : `float`\n",
      " |          upper corner frequency of pass band\n",
      " |      \n",
      " |      gpass : `float`\n",
      " |          the maximum loss in the passband (dB).\n",
      " |      \n",
      " |      gstop : `float`\n",
      " |          the minimum attenuation in the stopband (dB).\n",
      " |      \n",
      " |      fstop : `tuple` of `float`, optional\n",
      " |          `(low, high)` edge-frequencies of stop band\n",
      " |      \n",
      " |      type : `str`\n",
      " |          the filter type, either ``'iir'`` or ``'fir'``\n",
      " |      \n",
      " |      **kwargs\n",
      " |          other keyword arguments are passed to\n",
      " |          :func:`gwpy.signal.filter_design.bandpass`\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      bpseries : `TimeSeries`\n",
      " |          a band-passed version of the input `TimeSeries`\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      gwpy.signal.filter_design.bandpass\n",
      " |          for details on the filter design\n",
      " |      TimeSeries.filter\n",
      " |          for details on how the filter is applied\n",
      " |  \n",
      " |  coherence(self, other, fftlength=None, overlap=None, window='hann', **kwargs)\n",
      " |      Calculate the frequency-coherence between this `TimeSeries`\n",
      " |      and another.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : `TimeSeries`\n",
      " |          `TimeSeries` signal to calculate coherence with\n",
      " |      \n",
      " |      fftlength : `float`, optional\n",
      " |          number of seconds in single FFT, defaults to a single FFT\n",
      " |          covering the full duration\n",
      " |      \n",
      " |      overlap : `float`, optional\n",
      " |          number of seconds of overlap between FFTs, defaults to the\n",
      " |          recommended overlap for the given window (if given), or 0\n",
      " |      \n",
      " |      window : `str`, `numpy.ndarray`, optional\n",
      " |          window function to apply to timeseries prior to FFT,\n",
      " |          see :func:`scipy.signal.get_window` for details on acceptable\n",
      " |          formats\n",
      " |      \n",
      " |      **kwargs\n",
      " |          any other keyword arguments accepted by\n",
      " |          :func:`matplotlib.mlab.cohere` except ``NFFT``, ``window``,\n",
      " |          and ``noverlap`` which are superceded by the above keyword\n",
      " |          arguments\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      coherence : `~gwpy.frequencyseries.FrequencySeries`\n",
      " |          the coherence `FrequencySeries` of this `TimeSeries`\n",
      " |          with the other\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If `self` and `other` have difference\n",
      " |      :attr:`TimeSeries.sample_rate` values, the higher sampled\n",
      " |      `TimeSeries` will be down-sampled to match the lower.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      scipy.signal.coherence\n",
      " |          for details of the coherence calculator\n",
      " |  \n",
      " |  coherence_spectrogram(self, other, stride, fftlength=None, overlap=None, window='hann', nproc=1)\n",
      " |      Calculate the coherence spectrogram between this `TimeSeries`\n",
      " |      and other.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : `TimeSeries`\n",
      " |          the second `TimeSeries` in this CSD calculation\n",
      " |      \n",
      " |      stride : `float`\n",
      " |          number of seconds in single PSD (column of spectrogram)\n",
      " |      \n",
      " |      fftlength : `float`\n",
      " |          number of seconds in single FFT\n",
      " |      \n",
      " |      overlap : `float`, optional\n",
      " |          number of seconds of overlap between FFTs, defaults to the\n",
      " |          recommended overlap for the given window (if given), or 0\n",
      " |      \n",
      " |      window : `str`, `numpy.ndarray`, optional\n",
      " |          window function to apply to timeseries prior to FFT,\n",
      " |          see :func:`scipy.signal.get_window` for details on acceptable\n",
      " |          formats\n",
      " |      \n",
      " |      nproc : `int`\n",
      " |          number of parallel processes to use when calculating\n",
      " |          individual coherence spectra.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      spectrogram : `~gwpy.spectrogram.Spectrogram`\n",
      " |          time-frequency coherence spectrogram as generated from the\n",
      " |          input time-series.\n",
      " |  \n",
      " |  convolve(self, fir, window='hann')\n",
      " |      Convolve this `TimeSeries` with an FIR filter using the\n",
      " |         overlap-save method\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fir : `numpy.ndarray`\n",
      " |          the time domain filter to convolve with\n",
      " |      \n",
      " |      window : `str`, optional\n",
      " |          window function to apply to boundaries, default: ``'hann'``\n",
      " |          see :func:`scipy.signal.get_window` for details on acceptable\n",
      " |          formats\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out : `TimeSeries`\n",
      " |          the result of the convolution\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      scipy.signal.fftconvolve\n",
      " |          for details on the convolution scheme used here\n",
      " |      TimeSeries.filter\n",
      " |          for an alternative method designed for short filters\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The output `TimeSeries` is the same length and has the same timestamps\n",
      " |      as the input.\n",
      " |      \n",
      " |      Due to filter settle-in, a segment half the length of `fir` will be\n",
      " |      corrupted at the left and right boundaries. To prevent spectral leakage\n",
      " |      these segments will be windowed before convolving.\n",
      " |  \n",
      " |  correlate(self, mfilter, window='hann', detrend='linear', whiten=False, wduration=2, highpass=None, **asd_kw)\n",
      " |      Cross-correlate this `TimeSeries` with another signal\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      mfilter : `TimeSeries`\n",
      " |          the time domain signal to correlate with\n",
      " |      \n",
      " |      window : `str`, optional\n",
      " |          window function to apply to timeseries prior to FFT,\n",
      " |          default: ``'hann'``\n",
      " |          see :func:`scipy.signal.get_window` for details on acceptable\n",
      " |          formats\n",
      " |      \n",
      " |      detrend : `str`, optional\n",
      " |          type of detrending to do before FFT (see `~TimeSeries.detrend`\n",
      " |          for more details), default: ``'linear'``\n",
      " |      \n",
      " |      whiten : `bool`, optional\n",
      " |          boolean switch to enable (`True`) or disable (`False`) data\n",
      " |          whitening, default: `False`\n",
      " |      \n",
      " |      wduration : `float`, optional\n",
      " |          duration (in seconds) of the time-domain FIR whitening filter,\n",
      " |          only used if `whiten=True`, defaults to 2 seconds\n",
      " |      \n",
      " |      highpass : `float`, optional\n",
      " |          highpass corner frequency (in Hz) of the FIR whitening filter,\n",
      " |          only used if `whiten=True`, default: `None`\n",
      " |      \n",
      " |      **asd_kw\n",
      " |          keyword arguments to pass to `TimeSeries.asd` to generate\n",
      " |          an ASD, only used if `whiten=True`\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      snr : `TimeSeries`\n",
      " |          the correlated signal-to-noise ratio (SNR) timeseries\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      TimeSeries.asd\n",
      " |          for details on the ASD calculation\n",
      " |      TimeSeries.convolve\n",
      " |          for details on convolution with the overlap-save method\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The `window` argument is used in ASD estimation, whitening, and\n",
      " |      preventing spectral leakage in the output. It is not used to condition\n",
      " |      the matched-filter, which should be windowed before passing to this\n",
      " |      method.\n",
      " |      \n",
      " |      Due to filter settle-in, a segment half the length of `mfilter` will be\n",
      " |      corrupted at the beginning and end of the output. See\n",
      " |      `~TimeSeries.convolve` for more details.\n",
      " |      \n",
      " |      The input and matched-filter will be detrended, and the output will be\n",
      " |      normalised so that the SNR measures number of standard deviations from\n",
      " |      the expected mean.\n",
      " |  \n",
      " |  csd(self, other, fftlength=None, overlap=None, window='hann', **kwargs)\n",
      " |      Calculate the CSD `FrequencySeries` for two `TimeSeries`\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : `TimeSeries`\n",
      " |          the second `TimeSeries` in this CSD calculation\n",
      " |      \n",
      " |      fftlength : `float`\n",
      " |          number of seconds in single FFT, defaults to a single FFT\n",
      " |          covering the full duration\n",
      " |      \n",
      " |      overlap : `float`, optional\n",
      " |          number of seconds of overlap between FFTs, defaults to the\n",
      " |          recommended overlap for the given window (if given), or 0\n",
      " |      \n",
      " |      window : `str`, `numpy.ndarray`, optional\n",
      " |          window function to apply to timeseries prior to FFT,\n",
      " |          see :func:`scipy.signal.get_window` for details on acceptable\n",
      " |          formats\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      csd :  `~gwpy.frequencyseries.FrequencySeries`\n",
      " |          a data series containing the CSD.\n",
      " |  \n",
      " |  csd_spectrogram(self, other, stride, fftlength=None, overlap=0, window='hann', nproc=1, **kwargs)\n",
      " |      Calculate the cross spectral density spectrogram of this\n",
      " |         `TimeSeries` with 'other'.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : `~gwpy.timeseries.TimeSeries`\n",
      " |          second time-series for cross spectral density calculation\n",
      " |      \n",
      " |      stride : `float`\n",
      " |          number of seconds in single PSD (column of spectrogram).\n",
      " |      \n",
      " |      fftlength : `float`\n",
      " |          number of seconds in single FFT.\n",
      " |      \n",
      " |      overlap : `float`, optional\n",
      " |          number of seconds of overlap between FFTs, defaults to the\n",
      " |          recommended overlap for the given window (if given), or 0\n",
      " |      \n",
      " |      window : `str`, `numpy.ndarray`, optional\n",
      " |          window function to apply to timeseries prior to FFT,\n",
      " |          see :func:`scipy.signal.get_window` for details on acceptable\n",
      " |          formats\n",
      " |      \n",
      " |      nproc : `int`\n",
      " |          maximum number of independent frame reading processes, default\n",
      " |          is set to single-process file reading.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      spectrogram : `~gwpy.spectrogram.Spectrogram`\n",
      " |          time-frequency cross spectrogram as generated from the\n",
      " |          two input time-series.\n",
      " |  \n",
      " |  demodulate(self, f, stride=1, exp=False, deg=True)\n",
      " |      Compute the average magnitude and phase of this `TimeSeries`\n",
      " |      once per stride at a given frequency\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      f : `float`\n",
      " |          frequency (Hz) at which to demodulate the signal\n",
      " |      \n",
      " |      stride : `float`, optional\n",
      " |          stride (seconds) between calculations, defaults to 1 second\n",
      " |      \n",
      " |      exp : `bool`, optional\n",
      " |          return the magnitude and phase trends as one `TimeSeries` object\n",
      " |          representing a complex exponential, default: False\n",
      " |      \n",
      " |      deg : `bool`, optional\n",
      " |          if `exp=False`, calculates the phase in degrees\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      mag, phase : `TimeSeries`\n",
      " |          if `exp=False`, returns a pair of `TimeSeries` objects representing\n",
      " |          magnitude and phase trends with `dt=stride`\n",
      " |      \n",
      " |      out : `TimeSeries`\n",
      " |          if `exp=True`, returns a single `TimeSeries` with magnitude and\n",
      " |          phase trends represented as `mag * exp(1j*phase)` with `dt=stride`\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Demodulation is useful when trying to examine steady sinusoidal\n",
      " |      signals we know to be contained within data. For instance,\n",
      " |      we can download some data from GWOSC to look at trends of the\n",
      " |      amplitude and phase of LIGO Livingston's calibration line at 331.3 Hz:\n",
      " |      \n",
      " |      >>> from gwpy.timeseries import TimeSeries\n",
      " |      >>> data = TimeSeries.fetch_open_data('L1', 1131350417, 1131357617)\n",
      " |      \n",
      " |      We can demodulate the `TimeSeries` at 331.3 Hz with a stride of one\n",
      " |      minute:\n",
      " |      \n",
      " |      >>> amp, phase = data.demodulate(331.3, stride=60)\n",
      " |      \n",
      " |      We can then plot these trends to visualize fluctuations in the\n",
      " |      amplitude of the calibration line:\n",
      " |      \n",
      " |      >>> from gwpy.plot import Plot\n",
      " |      >>> plot = Plot(amp)\n",
      " |      >>> ax = plot.gca()\n",
      " |      >>> ax.set_ylabel('Strain Amplitude at 331.3 Hz')\n",
      " |      >>> plot.show()\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      TimeSeries.heterodyne\n",
      " |          for the underlying heterodyne detection method\n",
      " |  \n",
      " |  detrend(self, detrend='constant')\n",
      " |      Remove the trend from this `TimeSeries`\n",
      " |      \n",
      " |      This method just wraps :func:`scipy.signal.detrend` to return\n",
      " |      an object of the same type as the input.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      detrend : `str`, optional\n",
      " |          the type of detrending.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      detrended : `TimeSeries`\n",
      " |          the detrended input series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      scipy.signal.detrend\n",
      " |          for details on the options for the `detrend` argument, and\n",
      " |          how the operation is done\n",
      " |  \n",
      " |  fft(self, nfft=None)\n",
      " |      Compute the one-dimensional discrete Fourier transform of\n",
      " |      this `TimeSeries`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      nfft : `int`, optional\n",
      " |          length of the desired Fourier transform, input will be\n",
      " |          cropped or padded to match the desired length.\n",
      " |          If nfft is not given, the length of the `TimeSeries`\n",
      " |          will be used\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out : `~gwpy.frequencyseries.FrequencySeries`\n",
      " |          the normalised, complex-valued FFT `FrequencySeries`.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      numpy.fft.rfft : The FFT implementation used in this method.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method, in constrast to the :func:`numpy.fft.rfft` method\n",
      " |      it calls, applies the necessary normalisation such that the\n",
      " |      amplitude of the output `~gwpy.frequencyseries.FrequencySeries` is\n",
      " |      correct.\n",
      " |  \n",
      " |  fftgram(self, fftlength, overlap=None, window='hann', **kwargs)\n",
      " |      Calculate the Fourier-gram of this `TimeSeries`.\n",
      " |      \n",
      " |      At every ``stride``, a single, complex FFT is calculated.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fftlength : `float`\n",
      " |          number of seconds in single FFT.\n",
      " |      \n",
      " |      overlap : `float`, optional\n",
      " |          number of seconds of overlap between FFTs, defaults to the\n",
      " |          recommended overlap for the given window (if given), or 0\n",
      " |      \n",
      " |      window : `str`, `numpy.ndarray`, optional\n",
      " |          window function to apply to timeseries prior to FFT,\n",
      " |          see :func:`scipy.signal.get_window` for details on acceptable\n",
      " |      \n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |          a Fourier-gram\n",
      " |  \n",
      " |  filter(self, *filt, **kwargs)\n",
      " |      Filter this `TimeSeries` with an IIR or FIR filter\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      *filt : filter arguments\n",
      " |          1, 2, 3, or 4 arguments defining the filter to be applied,\n",
      " |      \n",
      " |              - an ``Nx1`` `~numpy.ndarray` of FIR coefficients\n",
      " |              - an ``Nx6`` `~numpy.ndarray` of SOS coefficients\n",
      " |              - ``(numerator, denominator)`` polynomials\n",
      " |              - ``(zeros, poles, gain)``\n",
      " |              - ``(A, B, C, D)`` 'state-space' representation\n",
      " |      \n",
      " |      filtfilt : `bool`, optional\n",
      " |          filter forward and backwards to preserve phase,\n",
      " |          default: `False`\n",
      " |      \n",
      " |      analog : `bool`, optional\n",
      " |          if `True`, filter coefficients will be converted from Hz\n",
      " |          to Z-domain digital representation, default: `False`\n",
      " |      \n",
      " |      inplace : `bool`, optional\n",
      " |          if `True`, this array will be overwritten with the filtered\n",
      " |          version, default: `False`\n",
      " |      \n",
      " |      **kwargs\n",
      " |          other keyword arguments are passed to the filter method\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : `TimeSeries`\n",
      " |          the filtered version of the input `TimeSeries`\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      IIR filters are converted into cascading second-order sections before\n",
      " |      being applied to this `TimeSeries`.\n",
      " |      \n",
      " |      FIR filters are passed directly to :func:`scipy.signal.lfilter` or\n",
      " |      :func:`scipy.signal.filtfilt` without any conversions.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      scipy.signal.sosfilt\n",
      " |          for details on filtering with second-order sections\n",
      " |      \n",
      " |      scipy.signal.sosfiltfilt\n",
      " |          for details on forward-backward filtering with second-order\n",
      " |          sections\n",
      " |      \n",
      " |      scipy.signal.lfilter\n",
      " |          for details on filtering (without SOS)\n",
      " |      \n",
      " |      scipy.signal.filtfilt\n",
      " |          for details on forward-backward filtering (without SOS)\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          if ``filt`` arguments cannot be interpreted properly\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      We can design an arbitrarily complicated filter using\n",
      " |      :mod:`gwpy.signal.filter_design`\n",
      " |      \n",
      " |      >>> from gwpy.signal import filter_design\n",
      " |      >>> bp = filter_design.bandpass(50, 250, 4096.)\n",
      " |      >>> notches = [filter_design.notch(f, 4096.) for f in (60, 120, 180)]\n",
      " |      >>> zpk = filter_design.concatenate_zpks(bp, *notches)\n",
      " |      \n",
      " |      And then can download some data from GWOSC to apply it using\n",
      " |      `TimeSeries.filter`:\n",
      " |      \n",
      " |      >>> from gwpy.timeseries import TimeSeries\n",
      " |      >>> data = TimeSeries.fetch_open_data('H1', 1126259446, 1126259478)\n",
      " |      >>> filtered = data.filter(zpk, filtfilt=True)\n",
      " |      \n",
      " |      We can plot the original signal, and the filtered version, cutting\n",
      " |      off either end of the filtered data to remove filter-edge artefacts\n",
      " |      \n",
      " |      >>> from gwpy.plot import Plot\n",
      " |      >>> plot = Plot(data, filtered[128:-128], separate=True)\n",
      " |      >>> plot.show()\n",
      " |  \n",
      " |  find_gates(self, tzero=1.0, whiten=True, threshold=50.0, cluster_window=0.5, **whiten_kwargs)\n",
      " |      Identify points that should be gates using a provided threshold\n",
      " |      and clustered within a provided time window.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      tzero : `int`, optional\n",
      " |          half-width time duration (seconds) in which the timeseries is\n",
      " |          set to zero\n",
      " |      \n",
      " |      whiten : `bool`, optional\n",
      " |          if True, data will be whitened before gating points are discovered,\n",
      " |          use of this option is highly recommended\n",
      " |      \n",
      " |      threshold : `float`, optional\n",
      " |          amplitude threshold, if the data exceeds this value a gating window\n",
      " |          will be placed\n",
      " |      \n",
      " |      cluster_window : `float`, optional\n",
      " |          time duration (seconds) over which gating points will be clustered\n",
      " |      \n",
      " |      **whiten_kwargs\n",
      " |          other keyword arguments that will be passed to the\n",
      " |          `TimeSeries.whiten` method if it is being used when discovering\n",
      " |          gating points\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out : `~gwpy.segments.SegmentList`\n",
      " |          a list of segments that should be gated based on the\n",
      " |          provided parameters\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      TimeSeries.gate\n",
      " |          for a method that applies the identified gates\n",
      " |  \n",
      " |  gate(self, tzero=1.0, tpad=0.5, whiten=True, threshold=50.0, cluster_window=0.5, **whiten_kwargs)\n",
      " |      Removes high amplitude peaks from data using inverse Planck window.\n",
      " |      \n",
      " |      Points will be discovered automatically using a provided threshold\n",
      " |      and clustered within a provided time window.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      tzero : `int`, optional\n",
      " |          half-width time duration (seconds) in which the timeseries is\n",
      " |          set to zero\n",
      " |      \n",
      " |      tpad : `int`, optional\n",
      " |          half-width time duration (seconds) in which the Planck window\n",
      " |          is tapered\n",
      " |      \n",
      " |      whiten : `bool`, optional\n",
      " |          if True, data will be whitened before gating points are discovered,\n",
      " |          use of this option is highly recommended\n",
      " |      \n",
      " |      threshold : `float`, optional\n",
      " |          amplitude threshold, if the data exceeds this value a gating window\n",
      " |          will be placed\n",
      " |      \n",
      " |      cluster_window : `float`, optional\n",
      " |          time duration (seconds) over which gating points will be clustered\n",
      " |      \n",
      " |      **whiten_kwargs\n",
      " |          other keyword arguments that will be passed to the\n",
      " |          `TimeSeries.whiten` method if it is being used when discovering\n",
      " |          gating points\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out : `~gwpy.timeseries.TimeSeries`\n",
      " |          a copy of the original `TimeSeries` that has had gating windows\n",
      " |          applied\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Read data into a `TimeSeries`\n",
      " |      \n",
      " |      >>> from gwpy.timeseries import TimeSeries\n",
      " |      >>> data = TimeSeries.fetch_open_data('H1', 1135148571, 1135148771)\n",
      " |      \n",
      " |      Apply gating using custom arguments\n",
      " |      \n",
      " |      >>> gated = data.gate(tzero=1.0, tpad=1.0, threshold=10.0,\n",
      " |                            fftlength=4, overlap=2, method='median')\n",
      " |      \n",
      " |      Plot the original data and the gated data, whiten both for\n",
      " |      visualization purposes\n",
      " |      \n",
      " |      >>> overlay = data.whiten(4,2,method='median').plot(dpi=150,\n",
      " |                                label='Ungated', color='dodgerblue',\n",
      " |                                zorder=2)\n",
      " |      >>> ax = overlay.gca()\n",
      " |      >>> ax.plot(gated.whiten(4,2,method='median'), label='Gated',\n",
      " |                  color='orange', zorder=3)\n",
      " |      >>> ax.set_xlim(1135148661, 1135148681)\n",
      " |      >>> ax.legend()\n",
      " |      >>> overlay.show()\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      TimeSeries.mask\n",
      " |          for the method that masks out unwanted data\n",
      " |      TimeSeries.find_gates\n",
      " |          for the method that identifies gating points\n",
      " |      TimeSeries.whiten\n",
      " |          for the whitening filter used to identify gating points\n",
      " |  \n",
      " |  heterodyne(self, phase, stride=1, singlesided=False)\n",
      " |      Compute the average magnitude and phase of this `TimeSeries`\n",
      " |      once per stride after heterodyning with a given phase series\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      phase : `array_like`\n",
      " |          an array of phase measurements (radians) with which to heterodyne\n",
      " |          the signal\n",
      " |      \n",
      " |      stride : `float`, optional\n",
      " |          stride (seconds) between calculations, defaults to 1 second\n",
      " |      \n",
      " |      singlesided : `bool`, optional\n",
      " |          Boolean switch to return single-sided output (i.e., to multiply by\n",
      " |          2 so that the signal is distributed across positive frequencies\n",
      " |          only), default: False\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out : `TimeSeries`\n",
      " |          magnitude and phase trends, represented as\n",
      " |          `mag * exp(1j*phase)` with `dt=stride`\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This is similar to the :meth:`~gwpy.timeseries.TimeSeries.demodulate`\n",
      " |      method, but is more general in that it accepts a varying phase\n",
      " |      evolution, rather than a fixed frequency.\n",
      " |      \n",
      " |      Unlike :meth:`~gwpy.timeseries.TimeSeries.demodulate`, the complex\n",
      " |      output is double-sided by default, so is not multiplied by 2.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Heterodyning can be useful in analysing quasi-monochromatic signals\n",
      " |      with a known phase evolution, such as continuous-wave signals\n",
      " |      from rapidly rotating neutron stars. These sources radiate at a\n",
      " |      frequency that slowly decreases over time, and is Doppler modulated\n",
      " |      due to the Earth's rotational and orbital motion.\n",
      " |      \n",
      " |      To see an example of heterodyning in action, we can simulate a signal\n",
      " |      whose phase evolution is described by the frequency and its first\n",
      " |      derivative with respect to time. We can download some O1 era\n",
      " |      LIGO-Livingston data from GWOSC, inject the simulated signal, and\n",
      " |      recover its amplitude.\n",
      " |      \n",
      " |      >>> from gwpy.timeseries import TimeSeries\n",
      " |      >>> data = TimeSeries.fetch_open_data('L1', 1131350417, 1131354017)\n",
      " |      \n",
      " |      We now need to set the signal parameters, generate the expected\n",
      " |      phase evolution, and create the signal:\n",
      " |      \n",
      " |      >>> import numpy\n",
      " |      >>> f0 = 123.456789  # signal frequency (Hz)\n",
      " |      >>> fdot = -9.87654321e-7  # signal frequency derivative (Hz/s)\n",
      " |      >>> fepoch = 1131350417  # phase epoch\n",
      " |      >>> amp = 1.5e-22  # signal amplitude\n",
      " |      >>> phase0 = 0.4  # signal phase at the phase epoch\n",
      " |      >>> times = data.times.value - fepoch\n",
      " |      >>> phase = 2 * numpy.pi * (f0 * times + 0.5 * fdot * times**2)\n",
      " |      >>> signal = TimeSeries(amp * numpy.cos(phase + phase0),\n",
      " |      >>>                     sample_rate=data.sample_rate, t0=data.t0)\n",
      " |      >>> data = data.inject(signal)\n",
      " |      \n",
      " |      To recover the signal, we can bandpass the injected data around the\n",
      " |      signal frequency, then heterodyne using our phase model with a stride\n",
      " |      of 60 seconds:\n",
      " |      \n",
      " |      >>> filtdata = data.bandpass(f0 - 0.5, f0 + 0.5)\n",
      " |      >>> het = filtdata.heterodyne(phase, stride=60, singlesided=True)\n",
      " |      \n",
      " |      We can then plot signal amplitude over time (cropping the first two\n",
      " |      minutes to remove the filter response):\n",
      " |      \n",
      " |      >>> plot = het.crop(het.x0.value + 180).abs().plot()\n",
      " |      >>> ax = plot.gca()\n",
      " |      >>> ax.set_ylabel(\"Strain amplitude\")\n",
      " |      >>> plot.show()\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      TimeSeries.demodulate\n",
      " |          for a method to heterodyne at a fixed frequency\n",
      " |  \n",
      " |  highpass(self, frequency, gpass=2, gstop=30, fstop=None, type='iir', filtfilt=True, **kwargs)\n",
      " |      Filter this `TimeSeries` with a high-pass filter.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      frequency : `float`\n",
      " |          high-pass corner frequency\n",
      " |      \n",
      " |      gpass : `float`\n",
      " |          the maximum loss in the passband (dB).\n",
      " |      \n",
      " |      gstop : `float`\n",
      " |          the minimum attenuation in the stopband (dB).\n",
      " |      \n",
      " |      fstop : `float`\n",
      " |          stop-band edge frequency, defaults to `frequency * 1.5`\n",
      " |      \n",
      " |      type : `str`\n",
      " |          the filter type, either ``'iir'`` or ``'fir'``\n",
      " |      \n",
      " |      **kwargs\n",
      " |          other keyword arguments are passed to\n",
      " |          :func:`gwpy.signal.filter_design.highpass`\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      hpseries : `TimeSeries`\n",
      " |          a high-passed version of the input `TimeSeries`\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      gwpy.signal.filter_design.highpass\n",
      " |          for details on the filter design\n",
      " |      TimeSeries.filter\n",
      " |          for details on how the filter is applied\n",
      " |  \n",
      " |  lowpass(self, frequency, gpass=2, gstop=30, fstop=None, type='iir', filtfilt=True, **kwargs)\n",
      " |      Filter this `TimeSeries` with a Butterworth low-pass filter.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      frequency : `float`\n",
      " |          low-pass corner frequency\n",
      " |      \n",
      " |      gpass : `float`\n",
      " |          the maximum loss in the passband (dB).\n",
      " |      \n",
      " |      gstop : `float`\n",
      " |          the minimum attenuation in the stopband (dB).\n",
      " |      \n",
      " |      fstop : `float`\n",
      " |          stop-band edge frequency, defaults to `frequency * 1.5`\n",
      " |      \n",
      " |      type : `str`\n",
      " |          the filter type, either ``'iir'`` or ``'fir'``\n",
      " |      \n",
      " |      **kwargs\n",
      " |          other keyword arguments are passed to\n",
      " |          :func:`gwpy.signal.filter_design.lowpass`\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      lpseries : `TimeSeries`\n",
      " |          a low-passed version of the input `TimeSeries`\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      gwpy.signal.filter_design.lowpass\n",
      " |          for details on the filter design\n",
      " |      TimeSeries.filter\n",
      " |          for details on how the filter is applied\n",
      " |  \n",
      " |  mask(self, deadtime=None, flag=None, query_open_data=False, const=nan, tpad=0.5, **kwargs)\n",
      " |      Mask away portions of this `TimeSeries` that fall within a given\n",
      " |      list of time segments\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deadtime : `SegmentList`, optional\n",
      " |          a list of time segments defining the deadtime (i.e., masked\n",
      " |          portions) of the output, will supersede `flag` if given\n",
      " |      \n",
      " |      flag : `str`, optional\n",
      " |          the name of a data-quality flag for which to query, required if\n",
      " |          `deadtime` is not given\n",
      " |      \n",
      " |      query_open_data : `bool`, optional\n",
      " |          if `True`, will query for publicly released data-quality segments\n",
      " |          through the Gravitational-wave Open Science Center (GWOSC),\n",
      " |          default: `False`\n",
      " |      \n",
      " |      const : `float`, optional\n",
      " |          constant value with which to mask deadtime data,\n",
      " |          default: `~numpy.nan`\n",
      " |      \n",
      " |      tpad : `float`, optional\n",
      " |          length of time (in seconds) over which to taper off data at\n",
      " |          mask segment boundaries, default: 0.5 seconds\n",
      " |      \n",
      " |      **kwargs : `dict`, optional\n",
      " |          additional keyword arguments to\n",
      " |          `~gwpy.segments.DataQualityFlag.query` or\n",
      " |          `~gwpy.segments.DataQualityFlag.fetch_open_data`,\n",
      " |          see \"Notes\" below\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out : `TimeSeries`\n",
      " |          the masked version of this `TimeSeries`\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If `tpad` is nonzero, the Planck-taper window is used to smoothly\n",
      " |      ramp data down to zero over a timescale `tpad` approaching every\n",
      " |      segment boundary in `deadtime`. However, this does not apply to\n",
      " |      the left or right bounds of the original `TimeSeries`.\n",
      " |      \n",
      " |      The `deadtime` segment list will always be coalesced and restricted to\n",
      " |      the limits of `self.span`. In particular, when querying a data-quality\n",
      " |      flag, this means the `start` and `end` arguments to\n",
      " |      `~gwpy.segments.DataQualityFlag.query` will effectively be reset and\n",
      " |      therefore need not be given.\n",
      " |      \n",
      " |      If `flag` is interpreted positively, i.e. if `flag` being active\n",
      " |      corresponds to a \"good\" state, then its complement in `self.span`\n",
      " |      will be used to define the deadtime for masking.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      gwpy.segments.DataQualityFlag.query\n",
      " |          for the method to query segments of a given data-quality flag\n",
      " |      gwpy.segments.DataQualityFlag.fetch_open_data\n",
      " |          for the method to query data-quality flags from the GWOSC database\n",
      " |      gwpy.signal.window.planck\n",
      " |          for the generic Planck-taper window\n",
      " |  \n",
      " |  notch(self, frequency, type='iir', filtfilt=True, **kwargs)\n",
      " |      Notch out a frequency in this `TimeSeries`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      frequency : `float`, `~astropy.units.Quantity`\n",
      " |          frequency (default in Hertz) at which to apply the notch\n",
      " |      \n",
      " |      type : `str`, optional\n",
      " |          type of filter to apply, currently only 'iir' is supported\n",
      " |      \n",
      " |      **kwargs\n",
      " |          other keyword arguments to pass to `scipy.signal.iirdesign`\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      notched : `TimeSeries`\n",
      " |         a notch-filtered copy of the input `TimeSeries`\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      TimeSeries.filter\n",
      " |         for details on the filtering method\n",
      " |      scipy.signal.iirdesign\n",
      " |          for details on the IIR filter design method\n",
      " |  \n",
      " |  psd(self, fftlength=None, overlap=None, window='hann', method='median', **kwargs)\n",
      " |      Calculate the PSD `FrequencySeries` for this `TimeSeries`\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fftlength : `float`\n",
      " |          number of seconds in single FFT, defaults to a single FFT\n",
      " |          covering the full duration\n",
      " |      \n",
      " |      overlap : `float`, optional\n",
      " |          number of seconds of overlap between FFTs, defaults to the\n",
      " |          recommended overlap for the given window (if given), or 0\n",
      " |      \n",
      " |      window : `str`, `numpy.ndarray`, optional\n",
      " |          window function to apply to timeseries prior to FFT,\n",
      " |          see :func:`scipy.signal.get_window` for details on acceptable\n",
      " |          formats\n",
      " |      \n",
      " |      method : `str`, optional\n",
      " |          FFT-averaging method (default: ``'median'``),\n",
      " |          see *Notes* for more details\n",
      " |      \n",
      " |      **kwargs\n",
      " |          other keyword arguments are passed to the underlying\n",
      " |          PSD-generation method\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      psd :  `~gwpy.frequencyseries.FrequencySeries`\n",
      " |          a data series containing the PSD.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The accepted ``method`` arguments are:\n",
      " |      \n",
      " |      - ``'bartlett'`` : a mean average of non-overlapping periodograms\n",
      " |      - ``'median'`` : a median average of overlapping periodograms\n",
      " |      - ``'welch'`` : a mean average of overlapping periodograms\n",
      " |  \n",
      " |  q_gram(self, qrange=(4, 64), frange=(0, inf), mismatch=0.2, snrthresh=5.5, **kwargs)\n",
      " |      Scan a `TimeSeries` using the multi-Q transform and return an\n",
      " |      `EventTable` of the most significant tiles\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      qrange : `tuple` of `float`, optional\n",
      " |          `(low, high)` range of Qs to scan\n",
      " |      \n",
      " |      frange : `tuple` of `float`, optional\n",
      " |          `(low, high)` range of frequencies to scan\n",
      " |      \n",
      " |      mismatch : `float`, optional\n",
      " |          maximum allowed fractional mismatch between neighbouring tiles\n",
      " |      \n",
      " |      snrthresh : `float`, optional\n",
      " |          lower inclusive threshold on individual tile SNR to keep in the\n",
      " |          table\n",
      " |      \n",
      " |      **kwargs\n",
      " |          other keyword arguments to be passed to :meth:`QTiling.transform`,\n",
      " |          including ``'epoch'`` and ``'search'``\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      qgram : `EventTable`\n",
      " |          a table of time-frequency tiles on the most significant `QPlane`\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      TimeSeries.q_transform\n",
      " |          for a method to interpolate the raw Q-transform over a regularly\n",
      " |          gridded spectrogram\n",
      " |      gwpy.signal.qtransform\n",
      " |          for code and documentation on how the Q-transform is implemented\n",
      " |      gwpy.table.EventTable.tile\n",
      " |          to render this `EventTable` as a collection of polygons\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Only tiles with signal energy greater than or equal to\n",
      " |      `snrthresh ** 2 / 2` will be stored in the output `EventTable`. The\n",
      " |      table columns are ``'time'``, ``'duration'``, ``'frequency'``,\n",
      " |      ``'bandwidth'``, and ``'energy'``.\n",
      " |  \n",
      " |  q_transform(self, qrange=(4, 64), frange=(0, inf), gps=None, search=0.5, tres='<default>', fres='<default>', logf=False, norm='median', mismatch=0.2, outseg=None, whiten=True, fduration=2, highpass=None, **asd_kw)\n",
      " |      Scan a `TimeSeries` using the multi-Q transform and return an\n",
      " |      interpolated high-resolution spectrogram\n",
      " |      \n",
      " |      By default, this method returns a high-resolution spectrogram in\n",
      " |      both time and frequency, which can result in a large memory\n",
      " |      footprint. If you know that you only need a subset of the output\n",
      " |      for, say, a figure, consider using ``outseg`` and the other\n",
      " |      keyword arguments to restrict the size of the returned data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      qrange : `tuple` of `float`, optional\n",
      " |          `(low, high)` range of Qs to scan\n",
      " |      \n",
      " |      frange : `tuple` of `float`, optional\n",
      " |          `(log, high)` range of frequencies to scan\n",
      " |      \n",
      " |      gps : `float`, optional\n",
      " |          central time of interest for determine loudest Q-plane\n",
      " |      \n",
      " |      search : `float`, optional\n",
      " |          window around `gps` in which to find peak energies, only\n",
      " |          used if `gps` is given\n",
      " |      \n",
      " |      tres : `float`, optional\n",
      " |          desired time resolution (seconds) of output `Spectrogram`,\n",
      " |          default is `abs(outseg) / 1000.`\n",
      " |      \n",
      " |      fres : `float`, `int`, `None`, optional\n",
      " |          desired frequency resolution (Hertz) of output `Spectrogram`,\n",
      " |          or, if ``logf=True``, the number of frequency samples;\n",
      " |          give `None` to skip this step and return the original resolution,\n",
      " |          default is 0.5 Hz or 500 frequency samples\n",
      " |      \n",
      " |      logf : `bool`, optional\n",
      " |          boolean switch to enable (`True`) or disable (`False`) use of\n",
      " |          log-sampled frequencies in the output `Spectrogram`,\n",
      " |          if `True` then `fres` is interpreted as a number of frequency\n",
      " |          samples, default: `False`\n",
      " |      \n",
      " |      norm : `bool`, `str`, optional\n",
      " |          whether to normalize the returned Q-transform output, or how,\n",
      " |          default: `True` (``'median'``), other options: `False`,\n",
      " |          ``'mean'``\n",
      " |      \n",
      " |      mismatch : `float`\n",
      " |          maximum allowed fractional mismatch between neighbouring tiles\n",
      " |      \n",
      " |      outseg : `~gwpy.segments.Segment`, optional\n",
      " |          GPS `[start, stop)` segment for output `Spectrogram`,\n",
      " |          default is the full duration of the input\n",
      " |      \n",
      " |      whiten : `bool`, `~gwpy.frequencyseries.FrequencySeries`, optional\n",
      " |          boolean switch to enable (`True`) or disable (`False`) data\n",
      " |          whitening, or an ASD `~gwpy.freqencyseries.FrequencySeries`\n",
      " |          with which to whiten the data\n",
      " |      \n",
      " |      fduration : `float`, optional\n",
      " |          duration (in seconds) of the time-domain FIR whitening filter,\n",
      " |          only used if `whiten` is not `False`, defaults to 2 seconds\n",
      " |      \n",
      " |      highpass : `float`, optional\n",
      " |          highpass corner frequency (in Hz) of the FIR whitening filter,\n",
      " |          used only if `whiten` is not `False`, default: `None`\n",
      " |      \n",
      " |      **asd_kw\n",
      " |          keyword arguments to pass to `TimeSeries.asd` to generate\n",
      " |          an ASD to use when whitening the data\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out : `~gwpy.spectrogram.Spectrogram`\n",
      " |          output `Spectrogram` of normalised Q energy\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      TimeSeries.asd\n",
      " |          for documentation on acceptable `**asd_kw`\n",
      " |      TimeSeries.whiten\n",
      " |          for documentation on how the whitening is done\n",
      " |      gwpy.signal.qtransform\n",
      " |          for code and documentation on how the Q-transform is implemented\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method will return a `Spectrogram` of dtype ``float32`` if\n",
      " |      ``norm`` is given, and ``float64`` otherwise.\n",
      " |      \n",
      " |      To optimize plot rendering with `~matplotlib.axes.Axes.pcolormesh`,\n",
      " |      the output `~gwpy.spectrogram.Spectrogram` can be given a log-sampled\n",
      " |      frequency axis by passing `logf=True` at runtime. The `fres` argument\n",
      " |      is then the number of points on the frequency axis. Note, this is\n",
      " |      incompatible with `~matplotlib.axes.Axes.imshow`.\n",
      " |      \n",
      " |      It is also highly recommended to use the `outseg` keyword argument\n",
      " |      when only a small window around a given GPS time is of interest. This\n",
      " |      will speed up this method a little, but can greatly speed up\n",
      " |      rendering the resulting `Spectrogram` using `pcolormesh`.\n",
      " |      \n",
      " |      If you aren't going to use `pcolormesh` in the end, don't worry.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> from numpy.random import normal\n",
      " |      >>> from scipy.signal import gausspulse\n",
      " |      >>> from gwpy.timeseries import TimeSeries\n",
      " |      \n",
      " |      Generate a `TimeSeries` containing Gaussian noise sampled at 4096 Hz,\n",
      " |      centred on GPS time 0, with a sine-Gaussian pulse ('glitch') at\n",
      " |      500 Hz:\n",
      " |      \n",
      " |      >>> noise = TimeSeries(normal(loc=1, size=4096*4), sample_rate=4096, epoch=-2)\n",
      " |      >>> glitch = TimeSeries(gausspulse(noise.times.value, fc=500) * 4, sample_rate=4096)\n",
      " |      >>> data = noise + glitch\n",
      " |      \n",
      " |      Compute and plot the Q-transform of these data:\n",
      " |      \n",
      " |      >>> q = data.q_transform()\n",
      " |      >>> plot = q.plot()\n",
      " |      >>> ax = plot.gca()\n",
      " |      >>> ax.set_xlim(-.2, .2)\n",
      " |      >>> ax.set_epoch(0)\n",
      " |      >>> plot.show()\n",
      " |  \n",
      " |  rayleigh_spectrogram(self, stride, fftlength=None, overlap=0, window='hann', nproc=1, **kwargs)\n",
      " |      Calculate the Rayleigh statistic spectrogram of this `TimeSeries`\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      stride : `float`\n",
      " |          number of seconds in single PSD (column of spectrogram).\n",
      " |      \n",
      " |      fftlength : `float`\n",
      " |          number of seconds in single FFT.\n",
      " |      \n",
      " |      overlap : `float`, optional\n",
      " |          number of seconds of overlap between FFTs, passing `None` will\n",
      " |          choose based on the window method, default: ``0``\n",
      " |      \n",
      " |      window : `str`, `numpy.ndarray`, optional\n",
      " |          window function to apply to timeseries prior to FFT,\n",
      " |          see :func:`scipy.signal.get_window` for details on acceptable\n",
      " |          formats\n",
      " |      \n",
      " |      nproc : `int`, optional\n",
      " |          maximum number of independent frame reading processes, default\n",
      " |          default: ``1``\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      spectrogram : `~gwpy.spectrogram.Spectrogram`\n",
      " |          time-frequency Rayleigh spectrogram as generated from the\n",
      " |          input time-series.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      TimeSeries.rayleigh\n",
      " |          for details of the statistic calculation\n",
      " |  \n",
      " |  rayleigh_spectrum(self, fftlength=None, overlap=0, window='hann')\n",
      " |      Calculate the Rayleigh `FrequencySeries` for this `TimeSeries`.\n",
      " |      \n",
      " |      The Rayleigh statistic is calculated as the ratio of the standard\n",
      " |      deviation and the mean of a number of periodograms.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fftlength : `float`\n",
      " |          number of seconds in single FFT, defaults to a single FFT\n",
      " |          covering the full duration\n",
      " |      \n",
      " |      overlap : `float`, optional\n",
      " |          number of seconds of overlap between FFTs, passing `None` will\n",
      " |          choose based on the window method, default: ``0``\n",
      " |      \n",
      " |      window : `str`, `numpy.ndarray`, optional\n",
      " |          window function to apply to timeseries prior to FFT,\n",
      " |          see :func:`scipy.signal.get_window` for details on acceptable\n",
      " |          formats\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      psd :  `~gwpy.frequencyseries.FrequencySeries`\n",
      " |          a data series containing the PSD.\n",
      " |  \n",
      " |  resample(self, rate, window='hamming', ftype='fir', n=None)\n",
      " |      Resample this Series to a new rate\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      rate : `float`\n",
      " |          rate to which to resample this `Series`\n",
      " |      \n",
      " |      window : `str`, `numpy.ndarray`, optional\n",
      " |          window function to apply to signal in the Fourier domain,\n",
      " |          see :func:`scipy.signal.get_window` for details on acceptable\n",
      " |          formats, only used for `ftype='fir'` or irregular downsampling\n",
      " |      \n",
      " |      ftype : `str`, optional\n",
      " |          type of filter, either 'fir' or 'iir', defaults to 'fir'\n",
      " |      \n",
      " |      n : `int`, optional\n",
      " |          if `ftype='fir'` the number of taps in the filter, otherwise\n",
      " |          the order of the Chebyshev type I IIR filter\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          a new Series with the resampling applied, and the same\n",
      " |          metadata\n",
      " |  \n",
      " |  rms(self, stride=1)\n",
      " |      Calculate the root-mean-square value of this `TimeSeries`\n",
      " |      once per stride.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      stride : `float`\n",
      " |          stride (seconds) between RMS calculations\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      rms : `TimeSeries`\n",
      " |          a new `TimeSeries` containing the RMS value with dt=stride\n",
      " |  \n",
      " |  spectral_variance(self, stride, fftlength=None, overlap=None, method='median', window='hann', nproc=1, filter=None, bins=None, low=None, high=None, nbins=500, log=False, norm=False, density=False)\n",
      " |      Calculate the `SpectralVariance` of this `TimeSeries`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      stride : `float`\n",
      " |          number of seconds in single PSD (column of spectrogram)\n",
      " |      \n",
      " |      fftlength : `float`\n",
      " |          number of seconds in single FFT\n",
      " |      \n",
      " |      method : `str`, optional\n",
      " |          FFT-averaging method (default: ``'median'``),\n",
      " |          see *Notes* for more details\n",
      " |      \n",
      " |      overlap : `float`, optional\n",
      " |          number of seconds of overlap between FFTs, defaults to the\n",
      " |          recommended overlap for the given window (if given), or 0\n",
      " |      \n",
      " |      window : `str`, `numpy.ndarray`, optional\n",
      " |          window function to apply to timeseries prior to FFT,\n",
      " |          see :func:`scipy.signal.get_window` for details on acceptable\n",
      " |          formats\n",
      " |      \n",
      " |      nproc : `int`\n",
      " |          maximum number of independent frame reading processes, default\n",
      " |          is set to single-process file reading.\n",
      " |      \n",
      " |      bins : `numpy.ndarray`, optional, default `None`\n",
      " |          array of histogram bin edges, including the rightmost edge\n",
      " |      \n",
      " |      low : `float`, optional\n",
      " |          left edge of lowest amplitude bin, only read\n",
      " |          if ``bins`` is not given\n",
      " |      \n",
      " |      high : `float`, optional\n",
      " |          right edge of highest amplitude bin, only read\n",
      " |          if ``bins`` is not given\n",
      " |      \n",
      " |      nbins : `int`, optional\n",
      " |          number of bins to generate, only read if ``bins`` is not\n",
      " |          given\n",
      " |      \n",
      " |      log : `bool`, optional\n",
      " |          calculate amplitude bins over a logarithmic scale, only\n",
      " |          read if ``bins`` is not given\n",
      " |      \n",
      " |      norm : `bool`, optional\n",
      " |          normalise bin counts to a unit sum\n",
      " |      \n",
      " |      density : `bool`, optional\n",
      " |          normalise bin counts to a unit integral\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      specvar : `SpectralVariance`\n",
      " |          2D-array of spectral frequency-amplitude counts\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      numpy.histogram\n",
      " |          for details on specifying bins and weights\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The accepted ``method`` arguments are:\n",
      " |      \n",
      " |      - ``'bartlett'`` : a mean average of non-overlapping periodograms\n",
      " |      - ``'median'`` : a median average of overlapping periodograms\n",
      " |      - ``'welch'`` : a mean average of overlapping periodograms\n",
      " |  \n",
      " |  spectrogram(self, stride, fftlength=None, overlap=None, window='hann', method='median', nproc=1, **kwargs)\n",
      " |      Calculate the average power spectrogram of this `TimeSeries`\n",
      " |      using the specified average spectrum method.\n",
      " |      \n",
      " |      Each time-bin of the output `Spectrogram` is calculated by taking\n",
      " |      a chunk of the `TimeSeries` in the segment\n",
      " |      `[t - overlap/2., t + stride + overlap/2.)` and calculating the\n",
      " |      :meth:`~gwpy.timeseries.TimeSeries.psd` of those data.\n",
      " |      \n",
      " |      As a result, each time-bin is calculated using `stride + overlap`\n",
      " |      seconds of data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      stride : `float`\n",
      " |          number of seconds in single PSD (column of spectrogram).\n",
      " |      \n",
      " |      fftlength : `float`\n",
      " |          number of seconds in single FFT.\n",
      " |      \n",
      " |      overlap : `float`, optional\n",
      " |          number of seconds of overlap between FFTs, defaults to the\n",
      " |          recommended overlap for the given window (if given), or 0\n",
      " |      \n",
      " |      window : `str`, `numpy.ndarray`, optional\n",
      " |          window function to apply to timeseries prior to FFT,\n",
      " |          see :func:`scipy.signal.get_window` for details on acceptable\n",
      " |          formats\n",
      " |      \n",
      " |      method : `str`, optional\n",
      " |          FFT-averaging method (default: ``'median'``),\n",
      " |          see *Notes* for more details\n",
      " |      \n",
      " |      nproc : `int`\n",
      " |          number of CPUs to use in parallel processing of FFTs\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      spectrogram : `~gwpy.spectrogram.Spectrogram`\n",
      " |          time-frequency power spectrogram as generated from the\n",
      " |          input time-series.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The accepted ``method`` arguments are:\n",
      " |      \n",
      " |      - ``'bartlett'`` : a mean average of non-overlapping periodograms\n",
      " |      - ``'median'`` : a median average of overlapping periodograms\n",
      " |      - ``'welch'`` : a mean average of overlapping periodograms\n",
      " |  \n",
      " |  spectrogram2(self, fftlength, overlap=None, window='hann', **kwargs)\n",
      " |      Calculate the non-averaged power `Spectrogram` of this `TimeSeries`\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fftlength : `float`\n",
      " |          number of seconds in single FFT.\n",
      " |      \n",
      " |      overlap : `float`, optional\n",
      " |          number of seconds of overlap between FFTs, defaults to the\n",
      " |          recommended overlap for the given window (if given), or 0\n",
      " |      \n",
      " |      window : `str`, `numpy.ndarray`, optional\n",
      " |          window function to apply to timeseries prior to FFT,\n",
      " |          see :func:`scipy.signal.get_window` for details on acceptable\n",
      " |          formats\n",
      " |      \n",
      " |      scaling : [ 'density' | 'spectrum' ], optional\n",
      " |          selects between computing the power spectral density ('density')\n",
      " |          where the `Spectrogram` has units of V**2/Hz if the input is\n",
      " |          measured in V and computing the power spectrum ('spectrum')\n",
      " |          where the `Spectrogram` has units of V**2 if the input is\n",
      " |          measured in V. Defaults to 'density'.\n",
      " |      \n",
      " |      **kwargs\n",
      " |          other parameters to be passed to `scipy.signal.periodogram` for\n",
      " |          each column of the `Spectrogram`\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      spectrogram: `~gwpy.spectrogram.Spectrogram`\n",
      " |          a power `Spectrogram` with `1/fftlength` frequency resolution and\n",
      " |          (fftlength - overlap) time resolution.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      scipy.signal.periodogram\n",
      " |          for documentation on the Fourier methods used in this calculation\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method calculates overlapping periodograms for all possible\n",
      " |      chunks of data entirely containing within the span of the input\n",
      " |      `TimeSeries`, then normalises the power in overlapping chunks using\n",
      " |      a triangular window centred on that chunk which most overlaps the\n",
      " |      given `Spectrogram` time sample.\n",
      " |  \n",
      " |  taper(self, side='leftright', duration=None, nsamples=None)\n",
      " |      Taper the ends of this `TimeSeries` smoothly to zero.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      side : `str`, optional\n",
      " |          the side of the `TimeSeries` to taper, must be one of `'left'`,\n",
      " |          `'right'`, or `'leftright'`\n",
      " |      \n",
      " |      duration : `float`, optional\n",
      " |          the duration of time to taper, will override `nsamples`\n",
      " |          if both are provided as arguments\n",
      " |      \n",
      " |      nsamples : `int`, optional\n",
      " |          the number of samples to taper, will be overridden by `duration`\n",
      " |          if both are provided as arguments\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out : `TimeSeries`\n",
      " |          a copy of `self` tapered at one or both ends\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          if `side` is not one of `('left', 'right', 'leftright')`\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      To see the effect of the Planck-taper window, we can taper a\n",
      " |      sinusoidal `TimeSeries` at both ends:\n",
      " |      \n",
      " |      >>> import numpy\n",
      " |      >>> from gwpy.timeseries import TimeSeries\n",
      " |      >>> t = numpy.linspace(0, 1, 2048)\n",
      " |      >>> series = TimeSeries(numpy.cos(10.5*numpy.pi*t), times=t)\n",
      " |      >>> tapered = series.taper()\n",
      " |      \n",
      " |      We can plot it to see how the ends now vary smoothly from 0 to 1:\n",
      " |      \n",
      " |      >>> from gwpy.plot import Plot\n",
      " |      >>> plot = Plot(series, tapered, separate=True, sharex=True)\n",
      " |      >>> plot.show()\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The :meth:`TimeSeries.taper` automatically tapers from the second\n",
      " |      stationary point (local maximum or minimum) on the specified side\n",
      " |      of the input. However, the method will never taper more than half\n",
      " |      the full width of the `TimeSeries`, and will fail if there are no\n",
      " |      stationary points.\n",
      " |      \n",
      " |      See :func:`~gwpy.signal.window.planck` for the generic Planck taper\n",
      " |      window, and see :func:`scipy.signal.get_window` for other common\n",
      " |      window formats.\n",
      " |  \n",
      " |  transfer_function(self, other, fftlength=None, overlap=None, window='hann', **kwargs)\n",
      " |      Calculate the transfer function between this `TimeSeries` and\n",
      " |      another.\n",
      " |      \n",
      " |      This `TimeSeries` is the 'A-channel', serving as the reference\n",
      " |      (denominator) while the other time series is the test (numerator)\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : `TimeSeries`\n",
      " |          `TimeSeries` signal to calculate the transfer function with\n",
      " |      \n",
      " |      fftlength : `float`, optional\n",
      " |          number of seconds in single FFT, defaults to a single FFT\n",
      " |          covering the full duration\n",
      " |      \n",
      " |      overlap : `float`, optional\n",
      " |          number of seconds of overlap between FFTs, defaults to the\n",
      " |          recommended overlap for the given window (if given), or 0\n",
      " |      \n",
      " |      window : `str`, `numpy.ndarray`, optional\n",
      " |          window function to apply to timeseries prior to FFT,\n",
      " |          see :func:`scipy.signal.get_window` for details on acceptable\n",
      " |          formats\n",
      " |      \n",
      " |      **kwargs\n",
      " |          any other keyword arguments accepted by\n",
      " |          :meth:`TimeSeries.csd` or :meth:`TimeSeries.psd`\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      transfer_function : `~gwpy.frequencyseries.FrequencySeries`\n",
      " |          the transfer function `FrequencySeries` of this `TimeSeries`\n",
      " |          with the other\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If `self` and `other` have difference\n",
      " |      :attr:`TimeSeries.sample_rate` values, the higher sampled\n",
      " |      `TimeSeries` will be down-sampled to match the lower.\n",
      " |  \n",
      " |  whiten(self, fftlength=None, overlap=0, method='median', window='hann', detrend='constant', asd=None, fduration=2, highpass=None, **kwargs)\n",
      " |      Whiten this `TimeSeries` using inverse spectrum truncation\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fftlength : `float`, optional\n",
      " |          FFT integration length (in seconds) for ASD estimation,\n",
      " |          default: choose based on sample rate\n",
      " |      \n",
      " |      overlap : `float`, optional\n",
      " |          number of seconds of overlap between FFTs, defaults to the\n",
      " |          recommended overlap for the given window (if given), or 0\n",
      " |      \n",
      " |      method : `str`, optional\n",
      " |          FFT-averaging method (default: ``'median'``)\n",
      " |      \n",
      " |      window : `str`, `numpy.ndarray`, optional\n",
      " |          window function to apply to timeseries prior to FFT,\n",
      " |          default: ``'hann'``\n",
      " |          see :func:`scipy.signal.get_window` for details on acceptable\n",
      " |          formats\n",
      " |      \n",
      " |      detrend : `str`, optional\n",
      " |          type of detrending to do before FFT (see `~TimeSeries.detrend`\n",
      " |          for more details), default: ``'constant'``\n",
      " |      \n",
      " |      asd : `~gwpy.frequencyseries.FrequencySeries`, optional\n",
      " |          the amplitude spectral density using which to whiten the data,\n",
      " |          overrides other ASD arguments, default: `None`\n",
      " |      \n",
      " |      fduration : `float`, optional\n",
      " |          duration (in seconds) of the time-domain FIR whitening filter,\n",
      " |          must be no longer than `fftlength`, default: 2 seconds\n",
      " |      \n",
      " |      highpass : `float`, optional\n",
      " |          highpass corner frequency (in Hz) of the FIR whitening filter,\n",
      " |          default: `None`\n",
      " |      \n",
      " |      **kwargs\n",
      " |          other keyword arguments are passed to the `TimeSeries.asd`\n",
      " |          method to estimate the amplitude spectral density\n",
      " |          `FrequencySeries` of this `TimeSeries`\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out : `TimeSeries`\n",
      " |          a whitened version of the input data with zero mean and unit\n",
      " |          variance\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      TimeSeries.asd\n",
      " |          for details on the ASD calculation\n",
      " |      TimeSeries.convolve\n",
      " |          for details on convolution with the overlap-save method\n",
      " |      gwpy.signal.filter_design.fir_from_transfer\n",
      " |          for FIR filter design through spectrum truncation\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The accepted ``method`` arguments are:\n",
      " |      \n",
      " |      - ``'bartlett'`` : a mean average of non-overlapping periodograms\n",
      " |      - ``'median'`` : a median average of overlapping periodograms\n",
      " |      - ``'welch'`` : a mean average of overlapping periodograms\n",
      " |      \n",
      " |      The ``window`` argument is used in ASD estimation, FIR filter design,\n",
      " |      and in preventing spectral leakage in the output.\n",
      " |      \n",
      " |      Due to filter settle-in, a segment of length ``0.5*fduration`` will be\n",
      " |      corrupted at the beginning and end of the output. See\n",
      " |      `~TimeSeries.convolve` for more details.\n",
      " |      \n",
      " |      The input is detrended and the output normalised such that, if the\n",
      " |      input is stationary and Gaussian, then the output will have zero mean\n",
      " |      and unit variance.\n",
      " |      \n",
      " |      For more on inverse spectrum truncation, see arXiv:gr-qc/0509116.\n",
      " |  \n",
      " |  zpk(self, zeros, poles, gain, analog=True, **kwargs)\n",
      " |      Filter this `TimeSeries` by applying a zero-pole-gain filter\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      zeros : `array-like`\n",
      " |          list of zero frequencies (in Hertz)\n",
      " |      \n",
      " |      poles : `array-like`\n",
      " |          list of pole frequencies (in Hertz)\n",
      " |      \n",
      " |      gain : `float`\n",
      " |          DC gain of filter\n",
      " |      \n",
      " |      analog : `bool`, optional\n",
      " |          type of ZPK being applied, if `analog=True` all parameters\n",
      " |          will be converted in the Z-domain for digital filtering\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      timeseries : `TimeSeries`\n",
      " |          the filtered version of the input data\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      TimeSeries.filter\n",
      " |          for details on how a digital ZPK-format filter is applied\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      To apply a zpk filter with file poles at 100 Hz, and five zeros at\n",
      " |      1 Hz (giving an overall DC gain of 1e-10)::\n",
      " |      \n",
      " |      >>> data2 = data.zpk([100]*5, [1]*5, 1e-10)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  DictClass = <class 'gwpy.timeseries.timeseries.TimeSeriesDict'>\n",
      " |      Ordered key-value mapping of named `TimeSeries` objects\n",
      " |      \n",
      " |      This object is designed to hold data for many different sources (channels)\n",
      " |      for a single time span.\n",
      " |      \n",
      " |      The main entry points for this object are the\n",
      " |      :meth:`~TimeSeriesDict.read` and :meth:`~TimeSeriesDict.fetch`\n",
      " |      data access methods.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from gwpy.timeseries.core.TimeSeriesBase:\n",
      " |  \n",
      " |  __array_ufunc__(self, ufunc, method, *inputs, **kwargs)\n",
      " |      Wrap numpy ufuncs, taking care of units.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      function : callable\n",
      " |          ufunc to wrap.\n",
      " |      method : str\n",
      " |          Ufunc method: ``__call__``, ``at``, ``reduce``, etc.\n",
      " |      inputs : tuple\n",
      " |          Input arrays.\n",
      " |      kwargs : keyword arguments\n",
      " |          As passed on, with ``out`` containing possible quantity output.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : `~astropy.units.Quantity`\n",
      " |          Results of the ufunc, with the unit set properly.\n",
      " |  \n",
      " |  __eq__(self, other)\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __ne__(self, other)\n",
      " |      Return self!=value.\n",
      " |  \n",
      " |  plot(self, method='plot', figsize=(12, 4), xscale='auto-gps', **kwargs)\n",
      " |      Plot the data for this timeseries\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      figure : `~matplotlib.figure.Figure`\n",
      " |          the newly created figure, with populated Axes.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      matplotlib.pyplot.figure\n",
      " |          for documentation of keyword arguments used to create the\n",
      " |          figure\n",
      " |      matplotlib.figure.Figure.add_subplot\n",
      " |          for documentation of keyword arguments used to create the\n",
      " |          axes\n",
      " |      matplotlib.axes.Axes.plot\n",
      " |          for documentation of keyword arguments used in rendering the data\n",
      " |  \n",
      " |  to_lal(self)\n",
      " |      Convert this `TimeSeries` into a LAL TimeSeries.\n",
      " |      \n",
      " |      .. note::\n",
      " |      \n",
      " |         This operation always copies data to new memory.\n",
      " |  \n",
      " |  to_pycbc(self, copy=True)\n",
      " |      Convert this `TimeSeries` into a PyCBC\n",
      " |      `~pycbc.types.timeseries.TimeSeries`\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      copy : `bool`, optional, default: `True`\n",
      " |          if `True`, copy these data to a new array\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      timeseries : `~pycbc.types.timeseries.TimeSeries`\n",
      " |          a PyCBC representation of this `TimeSeries`\n",
      " |  \n",
      " |  write(self, target, *args, **kwargs)\n",
      " |      Write this `TimeSeries` to a file\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      target : `str`\n",
      " |          path of output file\n",
      " |      \n",
      " |      format : `str`, optional\n",
      " |          output format identifier. If not given, the format will be\n",
      " |          detected if possible. See below for list of acceptable\n",
      " |          formats.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The available built-in formats are:\n",
      " |      \n",
      " |      ============ ==== ===== =============\n",
      " |         Format    Read Write Auto-identify\n",
      " |      ============ ==== ===== =============\n",
      " |               csv  Yes   Yes           Yes\n",
      " |               gwf  Yes   Yes           Yes\n",
      " |      gwf.framecpp  Yes   Yes            No\n",
      " |        gwf.framel  Yes   Yes            No\n",
      " |      gwf.lalframe  Yes   Yes            No\n",
      " |              hdf5  Yes   Yes           Yes\n",
      " |               txt  Yes   Yes           Yes\n",
      " |               wav  Yes   Yes            No\n",
      " |      ============ ==== ===== =============\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from gwpy.timeseries.core.TimeSeriesBase:\n",
      " |  \n",
      " |  fetch(channel, start, end, host=None, port=None, verbose=False, connection=None, verify=False, pad=None, allow_tape=None, scaled=None, type=None, dtype=None) from builtins.type\n",
      " |      Fetch data from NDS\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      channel : `str`, `~gwpy.detector.Channel`\n",
      " |          the data channel for which to query\n",
      " |      \n",
      " |      start : `~gwpy.time.LIGOTimeGPS`, `float`, `str`\n",
      " |          GPS start time of required data,\n",
      " |          any input parseable by `~gwpy.time.to_gps` is fine\n",
      " |      \n",
      " |      end : `~gwpy.time.LIGOTimeGPS`, `float`, `str`\n",
      " |          GPS end time of required data,\n",
      " |          any input parseable by `~gwpy.time.to_gps` is fine\n",
      " |      \n",
      " |      host : `str`, optional\n",
      " |          URL of NDS server to use, if blank will try any server\n",
      " |          (in a relatively sensible order) to get the data\n",
      " |      \n",
      " |      port : `int`, optional\n",
      " |          port number for NDS server query, must be given with `host`\n",
      " |      \n",
      " |      verify : `bool`, optional, default: `False`\n",
      " |          check channels exist in database before asking for data\n",
      " |      \n",
      " |      scaled : `bool`, optional\n",
      " |          apply slope and bias calibration to ADC data, for non-ADC data\n",
      " |          this option has no effect\n",
      " |      \n",
      " |      connection : `nds2.connection`, optional\n",
      " |          open NDS connection to use\n",
      " |      \n",
      " |      verbose : `bool`, optional\n",
      " |          print verbose output about NDS progress, useful for debugging;\n",
      " |          if ``verbose`` is specified as a string, this defines the\n",
      " |          prefix for the progress meter\n",
      " |      \n",
      " |      type : `int`, optional\n",
      " |          NDS2 channel type integer or string name to match\n",
      " |      \n",
      " |      dtype : `type`, `numpy.dtype`, `str`, optional\n",
      " |          NDS2 data type to match\n",
      " |  \n",
      " |  fetch_open_data(ifo, start, end, sample_rate=4096, tag=None, version=None, format='hdf5', host='https://www.gw-openscience.org', verbose=False, cache=None, **kwargs) from builtins.type\n",
      " |      Fetch open-access data from the LIGO Open Science Center\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ifo : `str`\n",
      " |          the two-character prefix of the IFO in which you are interested,\n",
      " |          e.g. `'L1'`\n",
      " |      \n",
      " |      start : `~gwpy.time.LIGOTimeGPS`, `float`, `str`, optional\n",
      " |          GPS start time of required data, defaults to start of data found;\n",
      " |          any input parseable by `~gwpy.time.to_gps` is fine\n",
      " |      \n",
      " |      end : `~gwpy.time.LIGOTimeGPS`, `float`, `str`, optional\n",
      " |          GPS end time of required data, defaults to end of data found;\n",
      " |          any input parseable by `~gwpy.time.to_gps` is fine\n",
      " |      \n",
      " |      sample_rate : `float`, optional,\n",
      " |          the sample rate of desired data; most data are stored\n",
      " |          by GWOSC at 4096 Hz, however there may be event-related\n",
      " |          data releases with a 16384 Hz rate, default: `4096`\n",
      " |      \n",
      " |      tag : `str`, optional\n",
      " |          file tag, e.g. ``'CLN'`` to select cleaned data, or ``'C00'``\n",
      " |          for 'raw' calibrated data.\n",
      " |      \n",
      " |      version : `int`, optional\n",
      " |          version of files to download, defaults to highest discovered\n",
      " |          version\n",
      " |      \n",
      " |      format : `str`, optional\n",
      " |          the data format to download and parse, default: ``'h5py'``\n",
      " |      \n",
      " |          - ``'hdf5'``\n",
      " |          - ``'gwf'`` - requires |LDAStools.frameCPP|_\n",
      " |      \n",
      " |      host : `str`, optional\n",
      " |          HTTP host name of GWOSC server to access\n",
      " |      \n",
      " |      verbose : `bool`, optional, default: `False`\n",
      " |          print verbose output while fetching data\n",
      " |      \n",
      " |      cache : `bool`, optional\n",
      " |          save/read a local copy of the remote URL, default: `False`;\n",
      " |          useful if the same remote data are to be accessed multiple times.\n",
      " |          Set `GWPY_CACHE=1` in the environment to auto-cache.\n",
      " |      \n",
      " |      **kwargs\n",
      " |          any other keyword arguments are passed to the `TimeSeries.read`\n",
      " |          method that parses the file that was downloaded\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> from gwpy.timeseries import (TimeSeries, StateVector)\n",
      " |      >>> print(TimeSeries.fetch_open_data('H1', 1126259446, 1126259478))\n",
      " |      TimeSeries([  2.17704028e-19,  2.08763900e-19,  2.39681183e-19,\n",
      " |                  ...,   3.55365541e-20,  6.33533516e-20,\n",
      " |                    7.58121195e-20]\n",
      " |                 unit: Unit(dimensionless),\n",
      " |                 t0: 1126259446.0 s,\n",
      " |                 dt: 0.000244140625 s,\n",
      " |                 name: Strain,\n",
      " |                 channel: None)\n",
      " |      >>> print(StateVector.fetch_open_data('H1', 1126259446, 1126259478))\n",
      " |      StateVector([127,127,127,127,127,127,127,127,127,127,127,127,\n",
      " |                   127,127,127,127,127,127,127,127,127,127,127,127,\n",
      " |                   127,127,127,127,127,127,127,127]\n",
      " |                  unit: Unit(dimensionless),\n",
      " |                  t0: 1126259446.0 s,\n",
      " |                  dt: 1.0 s,\n",
      " |                  name: Data quality,\n",
      " |                  channel: None,\n",
      " |                  bits: Bits(0: data present\n",
      " |                             1: passes cbc CAT1 test\n",
      " |                             2: passes cbc CAT2 test\n",
      " |                             3: passes cbc CAT3 test\n",
      " |                             4: passes burst CAT1 test\n",
      " |                             5: passes burst CAT2 test\n",
      " |                             6: passes burst CAT3 test,\n",
      " |                             channel=None,\n",
      " |                             epoch=1126259446.0))\n",
      " |      \n",
      " |      For the `StateVector`, the naming of the bits will be\n",
      " |      ``format``-dependent, because they are recorded differently by GWOSC\n",
      " |      in different formats.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      `StateVector` data are not available in ``txt.gz`` format.\n",
      " |  \n",
      " |  find(channel, start, end, frametype=None, pad=None, scaled=None, nproc=1, verbose=False, **readargs) from builtins.type\n",
      " |      Find and read data from frames for a channel\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      channel : `str`, `~gwpy.detector.Channel`\n",
      " |          the name of the channel to read, or a `Channel` object.\n",
      " |      \n",
      " |      start : `~gwpy.time.LIGOTimeGPS`, `float`, `str`\n",
      " |          GPS start time of required data,\n",
      " |          any input parseable by `~gwpy.time.to_gps` is fine\n",
      " |      \n",
      " |      end : `~gwpy.time.LIGOTimeGPS`, `float`, `str`\n",
      " |          GPS end time of required data,\n",
      " |          any input parseable by `~gwpy.time.to_gps` is fine\n",
      " |      \n",
      " |      frametype : `str`, optional\n",
      " |          name of frametype in which this channel is stored, will search\n",
      " |          for containing frame types if necessary\n",
      " |      \n",
      " |      nproc : `int`, optional, default: `1`\n",
      " |          number of parallel processes to use, serial process by\n",
      " |          default.\n",
      " |      \n",
      " |      pad : `float`, optional\n",
      " |          value with which to fill gaps in the source data,\n",
      " |          by default gaps will result in a `ValueError`.\n",
      " |      \n",
      " |      allow_tape : `bool`, optional, default: `True`\n",
      " |          allow reading from frame files on (slow) magnetic tape\n",
      " |      \n",
      " |      verbose : `bool`, optional\n",
      " |          print verbose output about read progress, if ``verbose``\n",
      " |          is specified as a string, this defines the prefix for the\n",
      " |          progress meter\n",
      " |      \n",
      " |      **readargs\n",
      " |          any other keyword arguments to be passed to `.read()`\n",
      " |  \n",
      " |  from_lal(lalts, copy=True) from builtins.type\n",
      " |      Generate a new TimeSeries from a LAL TimeSeries of any type.\n",
      " |  \n",
      " |  from_nds2_buffer(buffer_, scaled=None, copy=True, **metadata) from builtins.type\n",
      " |      Construct a new series from an `nds2.buffer` object\n",
      " |      \n",
      " |      **Requires:** |nds2|_\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      buffer_ : `nds2.buffer`\n",
      " |          the input NDS2-client buffer to read\n",
      " |      \n",
      " |      scaled : `bool`, optional\n",
      " |          apply slope and bias calibration to ADC data, for non-ADC data\n",
      " |          this option has no effect\n",
      " |      \n",
      " |      copy : `bool`, optional\n",
      " |          if `True`, copy the contained data array to new  to a new array\n",
      " |      \n",
      " |      **metadata\n",
      " |          any other metadata keyword arguments to pass to the `TimeSeries`\n",
      " |          constructor\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      timeseries : `TimeSeries`\n",
      " |          a new `TimeSeries` containing the data from the `nds2.buffer`,\n",
      " |          and the appropriate metadata\n",
      " |  \n",
      " |  from_pycbc(pycbcseries, copy=True) from builtins.type\n",
      " |      Convert a `pycbc.types.timeseries.TimeSeries` into a `TimeSeries`\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      pycbcseries : `pycbc.types.timeseries.TimeSeries`\n",
      " |          the input PyCBC `~pycbc.types.timeseries.TimeSeries` array\n",
      " |      \n",
      " |      copy : `bool`, optional, default: `True`\n",
      " |          if `True`, copy these data to a new array\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      timeseries : `TimeSeries`\n",
      " |          a GWpy version of the input timeseries\n",
      " |  \n",
      " |  get(channel, start, end, pad=None, scaled=None, dtype=None, verbose=False, allow_tape=None, **kwargs) from builtins.type\n",
      " |      Get data for this channel from frames or NDS\n",
      " |      \n",
      " |      This method dynamically accesses either frames on disk, or a\n",
      " |      remote NDS2 server to find and return data for the given interval\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      channel : `str`, `~gwpy.detector.Channel`\n",
      " |          the name of the channel to read, or a `Channel` object.\n",
      " |      \n",
      " |      start : `~gwpy.time.LIGOTimeGPS`, `float`, `str`\n",
      " |          GPS start time of required data,\n",
      " |          any input parseable by `~gwpy.time.to_gps` is fine\n",
      " |      \n",
      " |      end : `~gwpy.time.LIGOTimeGPS`, `float`, `str`\n",
      " |          GPS end time of required data,\n",
      " |          any input parseable by `~gwpy.time.to_gps` is fine\n",
      " |      \n",
      " |      pad : `float`, optional\n",
      " |          value with which to fill gaps in the source data,\n",
      " |          by default gaps will result in a `ValueError`.\n",
      " |      \n",
      " |      scaled : `bool`, optional\n",
      " |          apply slope and bias calibration to ADC data, for non-ADC data\n",
      " |          this option has no effect\n",
      " |      \n",
      " |      nproc : `int`, optional, default: `1`\n",
      " |          number of parallel processes to use, serial process by\n",
      " |          default.\n",
      " |      \n",
      " |      allow_tape : `bool`, optional, default: `None`\n",
      " |          allow the use of frames that are held on tape, default is `None`\n",
      " |          to attempt to allow the `TimeSeries.fetch` method to\n",
      " |          intelligently select a server that doesn't use tapes for\n",
      " |          data storage (doesn't always work), but to eventually allow\n",
      " |          retrieving data from tape if required\n",
      " |      \n",
      " |      verbose : `bool`, optional\n",
      " |          print verbose output about data access progress, if ``verbose``\n",
      " |          is specified as a string, this defines the prefix for the\n",
      " |          progress meter\n",
      " |      \n",
      " |      **kwargs\n",
      " |          other keyword arguments to pass to either\n",
      " |          :meth:`.find` (for direct GWF file access) or\n",
      " |          :meth:`.fetch` for remote NDS2 access\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      TimeSeries.fetch\n",
      " |          for grabbing data from a remote NDS2 server\n",
      " |      TimeSeries.find\n",
      " |          for discovering and reading data from local GWF files\n",
      " |  \n",
      " |  read(source, *args, **kwargs) from builtins.type\n",
      " |      Read data into a `TimeSeries`\n",
      " |      \n",
      " |      Arguments and keywords depend on the output format, see the\n",
      " |      online documentation for full details for each format, the parameters\n",
      " |      below are common to most formats.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      source : `str`, `list`\n",
      " |          Source of data, any of the following:\n",
      " |      \n",
      " |          - `str` path of single data file,\n",
      " |          - `str` path of LAL-format cache file,\n",
      " |          - `list` of paths.\n",
      " |      \n",
      " |      name : `str`, `~gwpy.detector.Channel`\n",
      " |          the name of the channel to read, or a `Channel` object.\n",
      " |      \n",
      " |      start : `~gwpy.time.LIGOTimeGPS`, `float`, `str`, optional\n",
      " |          GPS start time of required data, defaults to start of data found;\n",
      " |          any input parseable by `~gwpy.time.to_gps` is fine\n",
      " |      \n",
      " |      end : `~gwpy.time.LIGOTimeGPS`, `float`, `str`, optional\n",
      " |          GPS end time of required data, defaults to end of data found;\n",
      " |          any input parseable by `~gwpy.time.to_gps` is fine\n",
      " |      \n",
      " |      format : `str`, optional\n",
      " |          source format identifier. If not given, the format will be\n",
      " |          detected if possible. See below for list of acceptable\n",
      " |          formats.\n",
      " |      \n",
      " |      nproc : `int`, optional\n",
      " |          number of parallel processes to use, serial process by\n",
      " |          default.\n",
      " |      \n",
      " |      pad : `float`, optional\n",
      " |          value with which to fill gaps in the source data,\n",
      " |          by default gaps will result in a `ValueError`.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      IndexError\n",
      " |          if ``source`` is an empty list\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The available built-in formats are:\n",
      " |      \n",
      " |      ============ ==== ===== =============\n",
      " |         Format    Read Write Auto-identify\n",
      " |      ============ ==== ===== =============\n",
      " |               csv  Yes   Yes           Yes\n",
      " |               gwf  Yes   Yes           Yes\n",
      " |      gwf.framecpp  Yes   Yes            No\n",
      " |        gwf.framel  Yes   Yes            No\n",
      " |      gwf.lalframe  Yes   Yes            No\n",
      " |              hdf5  Yes   Yes           Yes\n",
      " |        hdf5.gwosc  Yes    No            No\n",
      " |               txt  Yes   Yes           Yes\n",
      " |               wav  Yes    No            No\n",
      " |      ============ ==== ===== =============\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from gwpy.timeseries.core.TimeSeriesBase:\n",
      " |  \n",
      " |  __new__(cls, data, unit=None, t0=None, dt=None, sample_rate=None, times=None, channel=None, name=None, **kwargs)\n",
      " |      Generate a new `TimeSeriesBase`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from gwpy.timeseries.core.TimeSeriesBase:\n",
      " |  \n",
      " |  duration\n",
      " |      Duration of this series in seconds\n",
      " |      \n",
      " |      :type: `~astropy.units.Quantity` scalar\n",
      " |  \n",
      " |  span\n",
      " |      X-axis [low, high) segment encompassed by these data\n",
      " |      \n",
      " |      :type: `~gwpy.segments.Segment`\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from gwpy.timeseries.core.TimeSeriesBase:\n",
      " |  \n",
      " |  dt\n",
      " |      X-axis sample separation\n",
      " |      \n",
      " |      :type: `~astropy.units.Quantity` scalar\n",
      " |  \n",
      " |  epoch\n",
      " |      GPS epoch for these data.\n",
      " |      \n",
      " |      This attribute is stored internally by the `t0` attribute\n",
      " |      \n",
      " |      :type: `~astropy.time.Time`\n",
      " |  \n",
      " |  sample_rate\n",
      " |      Data rate for this `TimeSeries` in samples per second (Hertz).\n",
      " |      \n",
      " |      This attribute is stored internally by the `dx` attribute\n",
      " |      \n",
      " |      :type: `~astropy.units.Quantity` scalar\n",
      " |  \n",
      " |  t0\n",
      " |      X-axis coordinate of the first data point\n",
      " |      \n",
      " |      :type: `~astropy.units.Quantity` scalar\n",
      " |  \n",
      " |  times\n",
      " |      Positions of the data on the x-axis\n",
      " |      \n",
      " |      :type: `~astropy.units.Quantity` array\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from gwpy.timeseries.core.TimeSeriesBase:\n",
      " |  \n",
      " |  __hash__ = None\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from gwpy.types.series.Series:\n",
      " |  \n",
      " |  __array_finalize__(self, obj)\n",
      " |      a.__array_finalize__(obj, /)\n",
      " |      \n",
      " |      Present so subclasses can call super. Does nothing.\n",
      " |  \n",
      " |  __getitem__(self, item)\n",
      " |      Return self[key].\n",
      " |  \n",
      " |  __getslice__(self, i, j)\n",
      " |  \n",
      " |  append(self, other, inplace=True, pad=None, gap=None, resize=True)\n",
      " |      Connect another series onto the end of the current one.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : `Series`\n",
      " |          another series of the same type to connect to this one\n",
      " |      \n",
      " |      inplace : `bool`, optional\n",
      " |          perform operation in-place, modifying current series,\n",
      " |          otherwise copy data and return new series, default: `True`\n",
      " |      \n",
      " |          .. warning::\n",
      " |      \n",
      " |             `inplace` append bypasses the reference check in\n",
      " |             `numpy.ndarray.resize`, so be carefully to only use this\n",
      " |             for arrays that haven't been sharing their memory!\n",
      " |      \n",
      " |      pad : `float`, optional\n",
      " |          value with which to pad discontiguous series,\n",
      " |          by default gaps will result in a `ValueError`.\n",
      " |      \n",
      " |      gap : `str`, optional\n",
      " |          action to perform if there's a gap between the other series\n",
      " |          and this one. One of\n",
      " |      \n",
      " |          - ``'raise'`` - raise a `ValueError`\n",
      " |          - ``'ignore'`` - remove gap and join data\n",
      " |          - ``'pad'`` - pad gap with zeros\n",
      " |      \n",
      " |          If ``pad`` is given and is not `None`, the default is ``'pad'``,\n",
      " |          otherwise ``'raise'``. If ``gap='pad'`` is given, the default\n",
      " |          for ``pad`` is ``0``.\n",
      " |      \n",
      " |      resize : `bool`, optional\n",
      " |          resize this array to accommodate new data, otherwise shift the\n",
      " |          old data to the left (potentially falling off the start) and\n",
      " |          put the new data in at the end, default: `True`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      series : `Series`\n",
      " |          a new series containing joined data sets\n",
      " |  \n",
      " |  copy(self, order='C')\n",
      " |      a.copy(order='C')\n",
      " |      \n",
      " |      Return a copy of the array.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      order : {'C', 'F', 'A', 'K'}, optional\n",
      " |          Controls the memory layout of the copy. 'C' means C-order,\n",
      " |          'F' means F-order, 'A' means 'F' if `a` is Fortran contiguous,\n",
      " |          'C' otherwise. 'K' means match the layout of `a` as closely\n",
      " |          as possible. (Note that this function and :func:`numpy.copy` are very\n",
      " |          similar but have different default values for their order=\n",
      " |          arguments, and this function always passes sub-classes through.)\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      numpy.copy : Similar function with different default behavior\n",
      " |      numpy.copyto\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This function is the preferred method for creating an array copy.  The\n",
      " |      function :func:`numpy.copy` is similar, but it defaults to using order 'K',\n",
      " |      and will not pass sub-classes through by default.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> x = np.array([[1,2,3],[4,5,6]], order='F')\n",
      " |      \n",
      " |      >>> y = x.copy()\n",
      " |      \n",
      " |      >>> x.fill(0)\n",
      " |      \n",
      " |      >>> x\n",
      " |      array([[0, 0, 0],\n",
      " |             [0, 0, 0]])\n",
      " |      \n",
      " |      >>> y\n",
      " |      array([[1, 2, 3],\n",
      " |             [4, 5, 6]])\n",
      " |      \n",
      " |      >>> y.flags['C_CONTIGUOUS']\n",
      " |      True\n",
      " |  \n",
      " |  crop(self, start=None, end=None, copy=False)\n",
      " |      Crop this series to the given x-axis extent.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      start : `float`, optional\n",
      " |          lower limit of x-axis to crop to, defaults to\n",
      " |          current `~Series.x0`\n",
      " |      \n",
      " |      end : `float`, optional\n",
      " |          upper limit of x-axis to crop to, defaults to current series end\n",
      " |      \n",
      " |      copy : `bool`, optional, default: `False`\n",
      " |          copy the input data to fresh memory, otherwise return a view\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      series : `Series`\n",
      " |          A new series with a sub-set of the input data\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If either ``start`` or ``end`` are outside of the original\n",
      " |      `Series` span, warnings will be printed and the limits will\n",
      " |      be restricted to the :attr:`~Series.xspan`\n",
      " |  \n",
      " |  diff(self, n=1, axis=-1)\n",
      " |      Calculate the n-th order discrete difference along given axis.\n",
      " |      \n",
      " |      The first order difference is given by ``out[n] = a[n+1] - a[n]`` along\n",
      " |      the given axis, higher order differences are calculated by using `diff`\n",
      " |      recursively.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int, optional\n",
      " |          The number of times values are differenced.\n",
      " |      axis : int, optional\n",
      " |          The axis along which the difference is taken, default is the\n",
      " |          last axis.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      diff : `Series`\n",
      " |          The `n` order differences. The shape of the output is the same\n",
      " |          as the input, except along `axis` where the dimension is\n",
      " |          smaller by `n`.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      numpy.diff\n",
      " |          for documentation on the underlying method\n",
      " |  \n",
      " |  inject(self, other)\n",
      " |      Add two compatible `Series` along their shared x-axis values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : `Series`\n",
      " |          a `Series` whose xindex intersects with `self.xindex`\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out : `Series`\n",
      " |          the sum of `self` and `other` along their shared x-axis values\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          if `self` and `other` have incompatible units or xindex intervals\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If `other.xindex` and `self.xindex` do not intersect, this method will\n",
      " |      return a copy of `self`. If the series have uniformly offset indices,\n",
      " |      this method will raise a warning.\n",
      " |      \n",
      " |      If `self.xindex` is an array of timestamps, and if `other.xspan` is\n",
      " |      not a subset of `self.xspan`, then `other` will be cropped before\n",
      " |      being adding to `self`.\n",
      " |      \n",
      " |      Users who wish to taper or window their `Series` should do so before\n",
      " |      passing it to this method. See :meth:`TimeSeries.taper` and\n",
      " |      :func:`~gwpy.signal.window.planck` for more information.\n",
      " |  \n",
      " |  is_compatible(self, other)\n",
      " |      Check whether this series and other have compatible metadata\n",
      " |      \n",
      " |      This method tests that the `sample size <Series.dx>`, and the\n",
      " |      `~Series.unit` match.\n",
      " |  \n",
      " |  is_contiguous(self, other, tol=3.814697265625e-06)\n",
      " |      Check whether other is contiguous with self.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : `Series`, `numpy.ndarray`\n",
      " |          another series of the same type to test for contiguity\n",
      " |      \n",
      " |      tol : `float`, optional\n",
      " |          the numerical tolerance of the test\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      1\n",
      " |          if `other` is contiguous with this series, i.e. would attach\n",
      " |          seamlessly onto the end\n",
      " |      -1\n",
      " |          if `other` is anti-contiguous with this seires, i.e. would attach\n",
      " |          seamlessly onto the start\n",
      " |      0\n",
      " |          if `other` is completely dis-contiguous with thie series\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      if a raw `numpy.ndarray` is passed as other, with no metadata, then\n",
      " |      the contiguity check will always pass\n",
      " |  \n",
      " |  pad(self, pad_width, **kwargs)\n",
      " |      Pad this series to a new size\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      pad_width : `int`, pair of `ints`\n",
      " |          number of samples by which to pad each end of the array;\n",
      " |          given a single `int` to pad both ends by the same amount,\n",
      " |          or a (before, after) `tuple` for assymetric padding\n",
      " |      \n",
      " |      **kwargs\n",
      " |          see :meth:`numpy.pad` for kwarg documentation\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      series : `Series`\n",
      " |          the padded version of the input\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      numpy.pad\n",
      " |          for details on the underlying functionality\n",
      " |  \n",
      " |  prepend(self, other, inplace=True, pad=None, gap=None, resize=True)\n",
      " |      Connect another series onto the start of the current one.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : `Series`\n",
      " |          another series of the same type as this one\n",
      " |      \n",
      " |      inplace : `bool`, optional\n",
      " |          perform operation in-place, modifying current series,\n",
      " |          otherwise copy data and return new series, default: `True`\n",
      " |      \n",
      " |          .. warning::\n",
      " |      \n",
      " |             `inplace` prepend bypasses the reference check in\n",
      " |             `numpy.ndarray.resize`, so be carefully to only use this\n",
      " |             for arrays that haven't been sharing their memory!\n",
      " |      \n",
      " |      pad : `float`, optional\n",
      " |          value with which to pad discontiguous series,\n",
      " |          by default gaps will result in a `ValueError`.\n",
      " |      \n",
      " |      gap : `str`, optional\n",
      " |          action to perform if there's a gap between the other series\n",
      " |          and this one. One of\n",
      " |      \n",
      " |          - ``'raise'`` - raise a `ValueError`\n",
      " |          - ``'ignore'`` - remove gap and join data\n",
      " |          - ``'pad'`` - pad gap with zeros\n",
      " |      \n",
      " |          If `pad` is given and is not `None`, the default is ``'pad'``,\n",
      " |          otherwise ``'raise'``.\n",
      " |      \n",
      " |      resize : `bool`, optional\n",
      " |          resize this array to accommodate new data, otherwise shift the\n",
      " |          old data to the left (potentially falling off the start) and\n",
      " |          put the new data in at the end, default: `True`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      series : `TimeSeries`\n",
      " |          time-series containing joined data sets\n",
      " |  \n",
      " |  shift(self, delta)\n",
      " |      Shift this `Series` forward on the X-axis by ``delta``\n",
      " |      \n",
      " |      This modifies the series in-place.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      delta : `float`, `~astropy.units.Quantity`, `str`\n",
      " |          The amount by which to shift (in x-axis units if `float`), give\n",
      " |          a negative value to shift backwards in time\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> from gwpy.types import Series\n",
      " |      >>> a = Series([1, 2, 3, 4, 5], x0=0, dx=1, xunit='m')\n",
      " |      >>> print(a.x0)\n",
      " |      0.0 m\n",
      " |      >>> a.shift(5)\n",
      " |      >>> print(a.x0)\n",
      " |      5.0 m\n",
      " |      >>> a.shift('-1 km')\n",
      " |      -995.0 m\n",
      " |  \n",
      " |  step(self, **kwargs)\n",
      " |      Create a step plot of this series\n",
      " |  \n",
      " |  update(self, other, inplace=True)\n",
      " |      Update this series by appending new data from an other\n",
      " |      and dropping the same amount of data off the start.\n",
      " |      \n",
      " |      This is a convenience method that just calls `~Series.append` with\n",
      " |      `resize=False`.\n",
      " |  \n",
      " |  value_at(self, x)\n",
      " |      Return the value of this `Series` at the given `xindex` value\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      x : `float`, `~astropy.units.Quantity`\n",
      " |          the `xindex` value at which to search\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : `~astropy.units.Quantity`\n",
      " |          the value of this Series at the given `xindex` value\n",
      " |  \n",
      " |  zip(self)\n",
      " |      Zip the `xindex` and `value` arrays of this `Series`\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      stacked : 2-d `numpy.ndarray`\n",
      " |          The array formed by stacking the the `xindex` and `value` of this\n",
      " |          series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = Series([0, 2, 4, 6, 8], xindex=[-5, -4, -3, -2, -1])\n",
      " |      >>> a.zip()\n",
      " |      array([[-5.,  0.],\n",
      " |             [-4.,  2.],\n",
      " |             [-3.,  4.],\n",
      " |             [-2.,  6.],\n",
      " |             [-1.,  8.]])\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from gwpy.types.series.Series:\n",
      " |  \n",
      " |  xspan\n",
      " |      X-axis [low, high) segment encompassed by these data\n",
      " |      \n",
      " |      :type: `~gwpy.segments.Segment`\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from gwpy.types.series.Series:\n",
      " |  \n",
      " |  dx\n",
      " |      X-axis sample separation\n",
      " |      \n",
      " |      :type: `~astropy.units.Quantity` scalar\n",
      " |  \n",
      " |  x0\n",
      " |      X-axis coordinate of the first data point\n",
      " |      \n",
      " |      :type: `~astropy.units.Quantity` scalar\n",
      " |  \n",
      " |  xindex\n",
      " |      Positions of the data on the x-axis\n",
      " |      \n",
      " |      :type: `~astropy.units.Quantity` array\n",
      " |  \n",
      " |  xunit\n",
      " |      Unit of x-axis index\n",
      " |      \n",
      " |      :type: `~astropy.units.Unit`\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from gwpy.types.array.Array:\n",
      " |  \n",
      " |  __getattr__(self, attr)\n",
      " |      Quantities are able to directly convert to other units that\n",
      " |      have the same physical type.\n",
      " |  \n",
      " |  __metadata_finalize__(self, obj, force=False)\n",
      " |  \n",
      " |  __quantity_subclass__(self, unit)\n",
      " |      Overridden by subclasses to change what kind of view is\n",
      " |      created based on the output unit of an operation.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      unit : UnitBase\n",
      " |          The unit for which the appropriate class should be returned\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      tuple :\n",
      " |          - `~astropy.units.Quantity` subclass\n",
      " |          - bool: True if subclasses of the given class are ok\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return a representation of this object\n",
      " |      \n",
      " |      This just represents each of the metadata objects appropriately\n",
      " |      after the core data array\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Return a printable string format representation of this object\n",
      " |      \n",
      " |      This just prints each of the metadata objects appropriately\n",
      " |      after the core data array\n",
      " |  \n",
      " |  abs(self, axis=None, **kwargs)\n",
      " |      absolute(x, /, out=None, *, where=True, casting='same_kind', order='K', dtype=None, subok=True[, signature, extobj])\n",
      " |      \n",
      " |      Calculate the absolute value element-wise.\n",
      " |      \n",
      " |      ``np.abs`` is a shorthand for this function.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      x : array_like\n",
      " |          Input array.\n",
      " |      out : ndarray, None, or tuple of ndarray and None, optional\n",
      " |          A location into which the result is stored. If provided, it must have\n",
      " |          a shape that the inputs broadcast to. If not provided or None,\n",
      " |          a freshly-allocated array is returned. A tuple (possible only as a\n",
      " |          keyword argument) must have length equal to the number of outputs.\n",
      " |      where : array_like, optional\n",
      " |          This condition is broadcast over the input. At locations where the\n",
      " |          condition is True, the `out` array will be set to the ufunc result.\n",
      " |          Elsewhere, the `out` array will retain its original value.\n",
      " |          Note that if an uninitialized `out` array is created via the default\n",
      " |          ``out=None``, locations within it where the condition is False will\n",
      " |          remain uninitialized.\n",
      " |      **kwargs\n",
      " |          For other keyword-only arguments, see the\n",
      " |          :ref:`ufunc docs <ufuncs.kwargs>`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      absolute : ndarray\n",
      " |          An ndarray containing the absolute value of\n",
      " |          each element in `x`.  For complex input, ``a + ib``, the\n",
      " |          absolute value is :math:`\\sqrt{ a^2 + b^2 }`.\n",
      " |          This is a scalar if `x` is a scalar.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> x = np.array([-1.2, 1.2])\n",
      " |      >>> np.absolute(x)\n",
      " |      array([ 1.2,  1.2])\n",
      " |      >>> np.absolute(1.2 + 1j)\n",
      " |      1.5620499351813308\n",
      " |      \n",
      " |      Plot the function over ``[-10, 10]``:\n",
      " |      \n",
      " |      >>> import matplotlib.pyplot as plt\n",
      " |      \n",
      " |      >>> x = np.linspace(start=-10, stop=10, num=101)\n",
      " |      >>> plt.plot(x, np.absolute(x))\n",
      " |      >>> plt.show()\n",
      " |      \n",
      " |      Plot the function over the complex plane:\n",
      " |      \n",
      " |      >>> xx = x + 1j * x[:, np.newaxis]\n",
      " |      >>> plt.imshow(np.abs(xx), extent=[-10, 10, -10, 10], cmap='gray')\n",
      " |      >>> plt.show()\n",
      " |      \n",
      " |      The `abs` function can be used as a shorthand for ``np.absolute`` on\n",
      " |      ndarrays.\n",
      " |      \n",
      " |      >>> x = np.array([-1.2, 1.2])\n",
      " |      >>> abs(x)\n",
      " |      array([1.2, 1.2])\n",
      " |  \n",
      " |  dumps(self)\n",
      " |      a.dumps()\n",
      " |      \n",
      " |      Returns the pickle of the array as a string.\n",
      " |      pickle.loads will convert the string back to an array.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      None\n",
      " |  \n",
      " |  flatten(self, order='C')\n",
      " |      Return a copy of the array collapsed into one dimension.\n",
      " |      \n",
      " |      Any index information is removed as part of the flattening,\n",
      " |      and the result is returned as a `~astropy.units.Quantity` array.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      order : {'C', 'F', 'A', 'K'}, optional\n",
      " |          'C' means to flatten in row-major (C-style) order.\n",
      " |          'F' means to flatten in column-major (Fortran-\n",
      " |          style) order. 'A' means to flatten in column-major\n",
      " |          order if `a` is Fortran *contiguous* in memory,\n",
      " |          row-major order otherwise. 'K' means to flatten\n",
      " |          `a` in the order the elements occur in memory.\n",
      " |          The default is 'C'.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : `~astropy.units.Quantity`\n",
      " |          A copy of the input array, flattened to one dimension.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      ravel : Return a flattened array.\n",
      " |      flat : A 1-D flat iterator over the array.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = Array([[1,2], [3,4]], unit='m', name='Test')\n",
      " |      >>> a.flatten()\n",
      " |      <Quantity [1., 2., 3., 4.] m>\n",
      " |  \n",
      " |  median(self, axis=None, **kwargs)\n",
      " |      Compute the median along the specified axis.\n",
      " |      \n",
      " |      Returns the median of the array elements.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      a : array_like\n",
      " |          Input array or object that can be converted to an array.\n",
      " |      axis : {int, sequence of int, None}, optional\n",
      " |          Axis or axes along which the medians are computed. The default\n",
      " |          is to compute the median along a flattened version of the array.\n",
      " |          A sequence of axes is supported since version 1.9.0.\n",
      " |      out : ndarray, optional\n",
      " |          Alternative output array in which to place the result. It must\n",
      " |          have the same shape and buffer length as the expected output,\n",
      " |          but the type (of the output) will be cast if necessary.\n",
      " |      overwrite_input : bool, optional\n",
      " |         If True, then allow use of memory of input array `a` for\n",
      " |         calculations. The input array will be modified by the call to\n",
      " |         `median`. This will save memory when you do not need to preserve\n",
      " |         the contents of the input array. Treat the input as undefined,\n",
      " |         but it will probably be fully or partially sorted. Default is\n",
      " |         False. If `overwrite_input` is ``True`` and `a` is not already an\n",
      " |         `ndarray`, an error will be raised.\n",
      " |      keepdims : bool, optional\n",
      " |          If this is set to True, the axes which are reduced are left\n",
      " |          in the result as dimensions with size one. With this option,\n",
      " |          the result will broadcast correctly against the original `arr`.\n",
      " |      \n",
      " |          .. versionadded:: 1.9.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      median : ndarray\n",
      " |          A new array holding the result. If the input contains integers\n",
      " |          or floats smaller than ``float64``, then the output data-type is\n",
      " |          ``np.float64``.  Otherwise, the data-type of the output is the\n",
      " |          same as that of the input. If `out` is specified, that array is\n",
      " |          returned instead.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      mean, percentile\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Given a vector ``V`` of length ``N``, the median of ``V`` is the\n",
      " |      middle value of a sorted copy of ``V``, ``V_sorted`` - i\n",
      " |      e., ``V_sorted[(N-1)/2]``, when ``N`` is odd, and the average of the\n",
      " |      two middle values of ``V_sorted`` when ``N`` is even.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = np.array([[10, 7, 4], [3, 2, 1]])\n",
      " |      >>> a\n",
      " |      array([[10,  7,  4],\n",
      " |             [ 3,  2,  1]])\n",
      " |      >>> np.median(a)\n",
      " |      3.5\n",
      " |      >>> np.median(a, axis=0)\n",
      " |      array([6.5, 4.5, 2.5])\n",
      " |      >>> np.median(a, axis=1)\n",
      " |      array([7.,  2.])\n",
      " |      >>> m = np.median(a, axis=0)\n",
      " |      >>> out = np.zeros_like(m)\n",
      " |      >>> np.median(a, axis=0, out=m)\n",
      " |      array([6.5,  4.5,  2.5])\n",
      " |      >>> m\n",
      " |      array([6.5,  4.5,  2.5])\n",
      " |      >>> b = a.copy()\n",
      " |      >>> np.median(b, axis=1, overwrite_input=True)\n",
      " |      array([7.,  2.])\n",
      " |      >>> assert not np.all(a==b)\n",
      " |      >>> b = a.copy()\n",
      " |      >>> np.median(b, axis=None, overwrite_input=True)\n",
      " |      3.5\n",
      " |      >>> assert not np.all(a==b)\n",
      " |  \n",
      " |  override_unit(self, unit, parse_strict='raise')\n",
      " |      Forcefully reset the unit of these data\n",
      " |      \n",
      " |      Use of this method is discouraged in favour of `to()`,\n",
      " |      which performs accurate conversions from one unit to another.\n",
      " |      The method should really only be used when the original unit of the\n",
      " |      array is plain wrong.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      unit : `~astropy.units.Unit`, `str`\n",
      " |          the unit to force onto this array\n",
      " |      parse_strict : `str`, optional\n",
      " |          how to handle errors in the unit parsing, default is to\n",
      " |          raise the underlying exception from `astropy.units`\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          if a `str` cannot be parsed as a valid unit\n",
      " |  \n",
      " |  tostring(self, order='C')\n",
      " |      a.tobytes(order='C')\n",
      " |      \n",
      " |      Construct Python bytes containing the raw data bytes in the array.\n",
      " |      \n",
      " |      Constructs Python bytes showing a copy of the raw contents of\n",
      " |      data memory. The bytes object is produced in C-order by default.\n",
      " |      This behavior is controlled by the ``order`` parameter.\n",
      " |      \n",
      " |      .. versionadded:: 1.9.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      order : {'C', 'F', 'A'}, optional\n",
      " |          Controls the memory layout of the bytes object. 'C' means C-order,\n",
      " |          'F' means F-order, 'A' (short for *Any*) means 'F' if `a` is\n",
      " |          Fortran contiguous, 'C' otherwise. Default is 'C'.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      s : bytes\n",
      " |          Python bytes exhibiting a copy of `a`'s raw data.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> x = np.array([[0, 1], [2, 3]], dtype='<u2')\n",
      " |      >>> x.tobytes()\n",
      " |      b'\\x00\\x00\\x01\\x00\\x02\\x00\\x03\\x00'\n",
      " |      >>> x.tobytes('C') == x.tobytes()\n",
      " |      True\n",
      " |      >>> x.tobytes('F')\n",
      " |      b'\\x00\\x00\\x02\\x00\\x01\\x00\\x03\\x00'\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from gwpy.types.array.Array:\n",
      " |  \n",
      " |  channel\n",
      " |      Instrumental channel associated with these data\n",
      " |      \n",
      " |      :type: `~gwpy.detector.Channel`\n",
      " |  \n",
      " |  name\n",
      " |      Name for this data set\n",
      " |      \n",
      " |      :type: `str`\n",
      " |  \n",
      " |  unit\n",
      " |      The physical unit of these data\n",
      " |      \n",
      " |      :type: `~astropy.units.UnitBase`\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from astropy.units.quantity.Quantity:\n",
      " |  \n",
      " |  __array_function__(self, function, types, args, kwargs)\n",
      " |      Wrap numpy functions, taking care of units.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      function : callable\n",
      " |          Numpy function to wrap\n",
      " |      types : iterable of classes\n",
      " |          Classes that provide an ``__array_function__`` override. Can\n",
      " |          in principle be used to interact with other classes. Below,\n",
      " |          mostly passed on to `~numpy.ndarray`, which can only interact\n",
      " |          with subclasses.\n",
      " |      args : tuple\n",
      " |          Positional arguments provided in the function call.\n",
      " |      kwargs : dict\n",
      " |          Keyword arguments provided in the function call.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result: `~astropy.units.Quantity`, `~numpy.ndarray`\n",
      " |          As appropriate for the function.  If the function is not\n",
      " |          supported, `NotImplemented` is returned, which will lead to\n",
      " |          a `TypeError` unless another argument overrode the function.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ~astropy.units.UnitsError\n",
      " |          If operands have incompatible units.\n",
      " |  \n",
      " |  __array_wrap__(self, obj, context=None)\n",
      " |      a.__array_wrap__(array[, context], /)\n",
      " |      \n",
      " |      Returns a view of `array` with the same type as self.\n",
      " |  \n",
      " |  __bool__(self)\n",
      " |      Quantities should always be treated as non-False; there is too much\n",
      " |      potential for ambiguity otherwise.\n",
      " |  \n",
      " |  __deepcopy__(self, memo)\n",
      " |      a.__deepcopy__(memo, /) -> Deep copy of array.\n",
      " |      \n",
      " |      Used if :func:`copy.deepcopy` is called on an array.\n",
      " |  \n",
      " |  __dir__(self)\n",
      " |      Quantities are able to directly convert to other units that\n",
      " |      have the same physical type.  This function is implemented in\n",
      " |      order to make autocompletion still work correctly in IPython.\n",
      " |  \n",
      " |  __float__(self)\n",
      " |      float(self)\n",
      " |  \n",
      " |  __format__(self, format_spec)\n",
      " |      Default object formatter.\n",
      " |  \n",
      " |  __ilshift__(self, other)\n",
      " |      Return self<<=value.\n",
      " |  \n",
      " |  __imul__(self, other)\n",
      " |      In-place multiplication between `Quantity` objects and others.\n",
      " |  \n",
      " |  __index__(self)\n",
      " |      Return self converted to an integer, if self is suitable for use as an index into a list.\n",
      " |  \n",
      " |  __int__(self)\n",
      " |      int(self)\n",
      " |  \n",
      " |  __irshift__(self, other)\n",
      " |      Return self>>=value.\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      Implement iter(self).\n",
      " |  \n",
      " |  __itruediv__(self, other)\n",
      " |      Inplace division between `Quantity` objects and other objects.\n",
      " |  \n",
      " |  __len__(self)\n",
      " |      Return len(self).\n",
      " |  \n",
      " |  __lshift__(self, other)\n",
      " |      Return self<<value.\n",
      " |  \n",
      " |  __mul__(self, other)\n",
      " |      Multiplication between `Quantity` objects and other objects.\n",
      " |  \n",
      " |  __pow__(self, other)\n",
      " |      Return pow(self, value, mod).\n",
      " |  \n",
      " |  __reduce__(self)\n",
      " |      a.__reduce__()\n",
      " |      \n",
      " |      For pickling.\n",
      " |  \n",
      " |  __rlshift__(self, other)\n",
      " |      Return value<<self.\n",
      " |  \n",
      " |  __rmul__(self, other)\n",
      " |      Right Multiplication between `Quantity` objects and other objects.\n",
      " |  \n",
      " |  __rrshift__(self, other)\n",
      " |      Return value>>self.\n",
      " |  \n",
      " |  __rshift__(self, other)\n",
      " |      Return self>>value.\n",
      " |  \n",
      " |  __rtruediv__(self, other)\n",
      " |      Right Division between `Quantity` objects and other objects.\n",
      " |  \n",
      " |  __setitem__(self, i, value)\n",
      " |      Set self[key] to value.\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |      a.__setstate__(state, /)\n",
      " |      \n",
      " |      For unpickling.\n",
      " |      \n",
      " |      The `state` argument must be a sequence that contains the following\n",
      " |      elements:\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      version : int\n",
      " |          optional pickle version. If omitted defaults to 0.\n",
      " |      shape : tuple\n",
      " |      dtype : data-type\n",
      " |      isFortran : bool\n",
      " |      rawdata : string or list\n",
      " |          a binary string with the data (or a list if 'a' is an object array)\n",
      " |  \n",
      " |  __truediv__(self, other)\n",
      " |      Division between `Quantity` objects and other objects.\n",
      " |  \n",
      " |  all(self, axis=None, out=None)\n",
      " |      a.all(axis=None, out=None, keepdims=False, *, where=True)\n",
      " |      \n",
      " |      Returns True if all elements evaluate to True.\n",
      " |      \n",
      " |      Refer to `numpy.all` for full documentation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.all : equivalent function\n",
      " |  \n",
      " |  any(self, axis=None, out=None)\n",
      " |      a.any(axis=None, out=None, keepdims=False, *, where=True)\n",
      " |      \n",
      " |      Returns True if any of the elements of `a` evaluate to True.\n",
      " |      \n",
      " |      Refer to `numpy.any` for full documentation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.any : equivalent function\n",
      " |  \n",
      " |  argmax(self, axis=None, out=None, *, keepdims=False)\n",
      " |      a.argmax(axis=None, out=None, *, keepdims=False)\n",
      " |      \n",
      " |      Return indices of the maximum values along the given axis.\n",
      " |      \n",
      " |      Refer to `numpy.argmax` for full documentation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.argmax : equivalent function\n",
      " |  \n",
      " |  argmin(self, axis=None, out=None, *, keepdims=False)\n",
      " |      a.argmin(axis=None, out=None, *, keepdims=False)\n",
      " |      \n",
      " |      Return indices of the minimum values along the given axis.\n",
      " |      \n",
      " |      Refer to `numpy.argmin` for detailed documentation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.argmin : equivalent function\n",
      " |  \n",
      " |  argsort(self, axis=-1, kind='quicksort', order=None)\n",
      " |      a.argsort(axis=-1, kind=None, order=None)\n",
      " |      \n",
      " |      Returns the indices that would sort this array.\n",
      " |      \n",
      " |      Refer to `numpy.argsort` for full documentation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.argsort : equivalent function\n",
      " |  \n",
      " |  choose(self, choices, out=None, mode='raise')\n",
      " |      a.choose(choices, out=None, mode='raise')\n",
      " |      \n",
      " |      Use an index array to construct a new array from a set of choices.\n",
      " |      \n",
      " |      Refer to `numpy.choose` for full documentation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.choose : equivalent function\n",
      " |  \n",
      " |  decompose(self, bases=[])\n",
      " |      Generates a new `Quantity` with the units\n",
      " |      decomposed. Decomposed units have only irreducible units in\n",
      " |      them (see `astropy.units.UnitBase.decompose`).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      bases : sequence of `~astropy.units.UnitBase`, optional\n",
      " |          The bases to decompose into.  When not provided,\n",
      " |          decomposes down to any irreducible units.  When provided,\n",
      " |          the decomposed result will only contain the given units.\n",
      " |          This will raises a `~astropy.units.UnitsError` if it's not possible\n",
      " |          to do so.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      newq : `~astropy.units.Quantity`\n",
      " |          A new object equal to this quantity with units decomposed.\n",
      " |  \n",
      " |  dot(self, b, out=None)\n",
      " |  \n",
      " |  dump(self, file)\n",
      " |      Not implemented, use ``.value.dump()`` instead.\n",
      " |  \n",
      " |  ediff1d(self, to_end=None, to_begin=None)\n",
      " |  \n",
      " |  fill(self, value)\n",
      " |      a.fill(value)\n",
      " |      \n",
      " |      Fill the array with a scalar value.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      value : scalar\n",
      " |          All elements of `a` will be assigned this value.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = np.array([1, 2])\n",
      " |      >>> a.fill(0)\n",
      " |      >>> a\n",
      " |      array([0, 0])\n",
      " |      >>> a = np.empty(2)\n",
      " |      >>> a.fill(1)\n",
      " |      >>> a\n",
      " |      array([1.,  1.])\n",
      " |  \n",
      " |  insert(self, obj, values, axis=None)\n",
      " |      Insert values along the given axis before the given indices and return\n",
      " |      a new `~astropy.units.Quantity` object.\n",
      " |      \n",
      " |      This is a thin wrapper around the `numpy.insert` function.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      obj : int, slice or sequence of int\n",
      " |          Object that defines the index or indices before which ``values`` is\n",
      " |          inserted.\n",
      " |      values : array-like\n",
      " |          Values to insert.  If the type of ``values`` is different\n",
      " |          from that of quantity, ``values`` is converted to the matching type.\n",
      " |          ``values`` should be shaped so that it can be broadcast appropriately\n",
      " |          The unit of ``values`` must be consistent with this quantity.\n",
      " |      axis : int, optional\n",
      " |          Axis along which to insert ``values``.  If ``axis`` is None then\n",
      " |          the quantity array is flattened before insertion.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out : `~astropy.units.Quantity`\n",
      " |          A copy of quantity with ``values`` inserted.  Note that the\n",
      " |          insertion does not occur in-place: a new quantity array is returned.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import astropy.units as u\n",
      " |      >>> q = [1, 2] * u.m\n",
      " |      >>> q.insert(0, 50 * u.cm)\n",
      " |      <Quantity [ 0.5,  1.,  2.] m>\n",
      " |      \n",
      " |      >>> q = [[1, 2], [3, 4]] * u.m\n",
      " |      >>> q.insert(1, [10, 20] * u.m, axis=0)\n",
      " |      <Quantity [[  1.,  2.],\n",
      " |                 [ 10., 20.],\n",
      " |                 [  3.,  4.]] m>\n",
      " |      \n",
      " |      >>> q.insert(1, 10 * u.m, axis=1)\n",
      " |      <Quantity [[  1., 10.,  2.],\n",
      " |                 [  3., 10.,  4.]] m>\n",
      " |  \n",
      " |  item(self, *args)\n",
      " |      Copy an element of an array to a scalar Quantity and return it.\n",
      " |      \n",
      " |      Like :meth:`~numpy.ndarray.item` except that it always\n",
      " |      returns a `Quantity`, not a Python scalar.\n",
      " |  \n",
      " |  itemset(self, *args)\n",
      " |      a.itemset(*args)\n",
      " |      \n",
      " |      Insert scalar into an array (scalar is cast to array's dtype, if possible)\n",
      " |      \n",
      " |      There must be at least 1 argument, and define the last argument\n",
      " |      as *item*.  Then, ``a.itemset(*args)`` is equivalent to but faster\n",
      " |      than ``a[args] = item``.  The item should be a scalar value and `args`\n",
      " |      must select a single item in the array `a`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      \\*args : Arguments\n",
      " |          If one argument: a scalar, only used in case `a` is of size 1.\n",
      " |          If two arguments: the last argument is the value to be set\n",
      " |          and must be a scalar, the first argument specifies a single array\n",
      " |          element location. It is either an int or a tuple.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Compared to indexing syntax, `itemset` provides some speed increase\n",
      " |      for placing a scalar into a particular location in an `ndarray`,\n",
      " |      if you must do this.  However, generally this is discouraged:\n",
      " |      among other problems, it complicates the appearance of the code.\n",
      " |      Also, when using `itemset` (and `item`) inside a loop, be sure\n",
      " |      to assign the methods to a local variable to avoid the attribute\n",
      " |      look-up at each loop iteration.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> np.random.seed(123)\n",
      " |      >>> x = np.random.randint(9, size=(3, 3))\n",
      " |      >>> x\n",
      " |      array([[2, 2, 6],\n",
      " |             [1, 3, 6],\n",
      " |             [1, 0, 1]])\n",
      " |      >>> x.itemset(4, 0)\n",
      " |      >>> x.itemset((2, 2), 9)\n",
      " |      >>> x\n",
      " |      array([[2, 2, 6],\n",
      " |             [1, 0, 6],\n",
      " |             [1, 0, 9]])\n",
      " |  \n",
      " |  mean(self, axis=None, dtype=None, out=None, keepdims=False, *, where=True)\n",
      " |      a.mean(axis=None, dtype=None, out=None, keepdims=False, *, where=True)\n",
      " |      \n",
      " |      Returns the average of the array elements along given axis.\n",
      " |      \n",
      " |      Refer to `numpy.mean` for full documentation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.mean : equivalent function\n",
      " |  \n",
      " |  nansum(self, axis=None, out=None, keepdims=False, *, initial=None, where=True)\n",
      " |      # TODO: deprecate this method? It is not on ndarray, and we do not\n",
      " |      # support nanmean, etc., so why this one?\n",
      " |  \n",
      " |  put(self, indices, values, mode='raise')\n",
      " |      a.put(indices, values, mode='raise')\n",
      " |      \n",
      " |      Set ``a.flat[n] = values[n]`` for all `n` in indices.\n",
      " |      \n",
      " |      Refer to `numpy.put` for full documentation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.put : equivalent function\n",
      " |  \n",
      " |  round(self, decimals=0, out=None)\n",
      " |      a.round(decimals=0, out=None)\n",
      " |      \n",
      " |      Return `a` with each element rounded to the given number of decimals.\n",
      " |      \n",
      " |      Refer to `numpy.around` for full documentation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.around : equivalent function\n",
      " |  \n",
      " |  searchsorted(self, v, *args, **kwargs)\n",
      " |      a.searchsorted(v, side='left', sorter=None)\n",
      " |      \n",
      " |      Find indices where elements of v should be inserted in a to maintain order.\n",
      " |      \n",
      " |      For full documentation, see `numpy.searchsorted`\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.searchsorted : equivalent function\n",
      " |  \n",
      " |  std(self, axis=None, dtype=None, out=None, ddof=0, keepdims=False, *, where=True)\n",
      " |      a.std(axis=None, dtype=None, out=None, ddof=0, keepdims=False, *, where=True)\n",
      " |      \n",
      " |      Returns the standard deviation of the array elements along given axis.\n",
      " |      \n",
      " |      Refer to `numpy.std` for full documentation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.std : equivalent function\n",
      " |  \n",
      " |  take(self, indices, axis=None, out=None, mode='raise')\n",
      " |      a.take(indices, axis=None, out=None, mode='raise')\n",
      " |      \n",
      " |      Return an array formed from the elements of `a` at the given indices.\n",
      " |      \n",
      " |      Refer to `numpy.take` for full documentation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.take : equivalent function\n",
      " |  \n",
      " |  to(self, unit, equivalencies=[], copy=True)\n",
      " |      Return a new `~astropy.units.Quantity` object with the specified unit.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      unit : unit-like\n",
      " |          An object that represents the unit to convert to. Must be\n",
      " |          an `~astropy.units.UnitBase` object or a string parseable\n",
      " |          by the `~astropy.units` package.\n",
      " |      \n",
      " |      equivalencies : list of tuple\n",
      " |          A list of equivalence pairs to try if the units are not\n",
      " |          directly convertible.  See :ref:`astropy:unit_equivalencies`.\n",
      " |          If not provided or ``[]``, class default equivalencies will be used\n",
      " |          (none for `~astropy.units.Quantity`, but may be set for subclasses)\n",
      " |          If `None`, no equivalencies will be applied at all, not even any\n",
      " |          set globally or within a context.\n",
      " |      \n",
      " |      copy : bool, optional\n",
      " |          If `True` (default), then the value is copied.  Otherwise, a copy\n",
      " |          will only be made if necessary.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      to_value : get the numerical value in a given unit.\n",
      " |  \n",
      " |  to_string(self, unit=None, precision=None, format=None, subfmt=None)\n",
      " |      Generate a string representation of the quantity and its unit.\n",
      " |      \n",
      " |      The behavior of this function can be altered via the\n",
      " |      `numpy.set_printoptions` function and its various keywords.  The\n",
      " |      exception to this is the ``threshold`` keyword, which is controlled via\n",
      " |      the ``[units.quantity]`` configuration item ``latex_array_threshold``.\n",
      " |      This is treated separately because the numpy default of 1000 is too big\n",
      " |      for most browsers to handle.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      unit : unit-like, optional\n",
      " |          Specifies the unit.  If not provided,\n",
      " |          the unit used to initialize the quantity will be used.\n",
      " |      \n",
      " |      precision : number, optional\n",
      " |          The level of decimal precision. If `None`, or not provided,\n",
      " |          it will be determined from NumPy print options.\n",
      " |      \n",
      " |      format : str, optional\n",
      " |          The format of the result. If not provided, an unadorned\n",
      " |          string is returned. Supported values are:\n",
      " |      \n",
      " |          - 'latex': Return a LaTeX-formatted string\n",
      " |      \n",
      " |          - 'latex_inline': Return a LaTeX-formatted string that uses\n",
      " |            negative exponents instead of fractions\n",
      " |      \n",
      " |      subfmt : str, optional\n",
      " |          Subformat of the result. For the moment, only used for\n",
      " |          ``format='latex'`` and ``format='latex_inline'``. Supported\n",
      " |          values are:\n",
      " |      \n",
      " |          - 'inline': Use ``$ ... $`` as delimiters.\n",
      " |      \n",
      " |          - 'display': Use ``$\\displaystyle ... $`` as delimiters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      str\n",
      " |          A string with the contents of this Quantity\n",
      " |  \n",
      " |  to_value(self, unit=None, equivalencies=[])\n",
      " |      The numerical value, possibly in a different unit.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      unit : unit-like, optional\n",
      " |          The unit in which the value should be given. If not given or `None`,\n",
      " |          use the current unit.\n",
      " |      \n",
      " |      equivalencies : list of tuple, optional\n",
      " |          A list of equivalence pairs to try if the units are not directly\n",
      " |          convertible (see :ref:`astropy:unit_equivalencies`). If not provided\n",
      " |          or ``[]``, class default equivalencies will be used (none for\n",
      " |          `~astropy.units.Quantity`, but may be set for subclasses).\n",
      " |          If `None`, no equivalencies will be applied at all, not even any\n",
      " |          set globally or within a context.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      value : ndarray or scalar\n",
      " |          The value in the units specified. For arrays, this will be a view\n",
      " |          of the data if no unit conversion was necessary.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      to : Get a new instance in a different unit.\n",
      " |  \n",
      " |  tobytes(self, order='C')\n",
      " |      Not implemented, use ``.value.tobytes()`` instead.\n",
      " |  \n",
      " |  tofile(self, fid, sep='', format='%s')\n",
      " |      Not implemented, use ``.value.tofile()`` instead.\n",
      " |  \n",
      " |  tolist(self)\n",
      " |      a.tolist()\n",
      " |      \n",
      " |      Return the array as an ``a.ndim``-levels deep nested list of Python scalars.\n",
      " |      \n",
      " |      Return a copy of the array data as a (nested) Python list.\n",
      " |      Data items are converted to the nearest compatible builtin Python type, via\n",
      " |      the `~numpy.ndarray.item` function.\n",
      " |      \n",
      " |      If ``a.ndim`` is 0, then since the depth of the nested list is 0, it will\n",
      " |      not be a list at all, but a simple Python scalar.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      none\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : object, or list of object, or list of list of object, or ...\n",
      " |          The possibly nested list of array elements.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The array may be recreated via ``a = np.array(a.tolist())``, although this\n",
      " |      may sometimes lose precision.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      For a 1D array, ``a.tolist()`` is almost the same as ``list(a)``,\n",
      " |      except that ``tolist`` changes numpy scalars to Python scalars:\n",
      " |      \n",
      " |      >>> a = np.uint32([1, 2])\n",
      " |      >>> a_list = list(a)\n",
      " |      >>> a_list\n",
      " |      [1, 2]\n",
      " |      >>> type(a_list[0])\n",
      " |      <class 'numpy.uint32'>\n",
      " |      >>> a_tolist = a.tolist()\n",
      " |      >>> a_tolist\n",
      " |      [1, 2]\n",
      " |      >>> type(a_tolist[0])\n",
      " |      <class 'int'>\n",
      " |      \n",
      " |      Additionally, for a 2D array, ``tolist`` applies recursively:\n",
      " |      \n",
      " |      >>> a = np.array([[1, 2], [3, 4]])\n",
      " |      >>> list(a)\n",
      " |      [array([1, 2]), array([3, 4])]\n",
      " |      >>> a.tolist()\n",
      " |      [[1, 2], [3, 4]]\n",
      " |      \n",
      " |      The base case for this recursion is a 0D array:\n",
      " |      \n",
      " |      >>> a = np.array(1)\n",
      " |      >>> list(a)\n",
      " |      Traceback (most recent call last):\n",
      " |        ...\n",
      " |      TypeError: iteration over a 0-d array\n",
      " |      >>> a.tolist()\n",
      " |      1\n",
      " |  \n",
      " |  trace(self, offset=0, axis1=0, axis2=1, dtype=None, out=None)\n",
      " |      a.trace(offset=0, axis1=0, axis2=1, dtype=None, out=None)\n",
      " |      \n",
      " |      Return the sum along diagonals of the array.\n",
      " |      \n",
      " |      Refer to `numpy.trace` for full documentation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.trace : equivalent function\n",
      " |  \n",
      " |  var(self, axis=None, dtype=None, out=None, ddof=0, keepdims=False, *, where=True)\n",
      " |      a.var(axis=None, dtype=None, out=None, ddof=0, keepdims=False, *, where=True)\n",
      " |      \n",
      " |      Returns the variance of the array elements, along given axis.\n",
      " |      \n",
      " |      Refer to `numpy.var` for full documentation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.var : equivalent function\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from astropy.units.quantity.Quantity:\n",
      " |  \n",
      " |  __class_getitem__(unit_shape_dtype) from builtins.type\n",
      " |      Quantity Type Hints.\n",
      " |      \n",
      " |      Unit-aware type hints are ``Annotated`` objects that encode the class,\n",
      " |      the unit, and possibly shape and dtype information, depending on the\n",
      " |      python and :mod:`numpy` versions.\n",
      " |      \n",
      " |      Schematically, ``Annotated[cls[shape, dtype], unit]``\n",
      " |      \n",
      " |      As a classmethod, the type is the class, ie ``Quantity``\n",
      " |      produces an ``Annotated[Quantity, ...]`` while a subclass\n",
      " |      like :class:`~astropy.coordinates.Angle` returns\n",
      " |      ``Annotated[Angle, ...]``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      unit_shape_dtype : :class:`~astropy.units.UnitBase`, str, `~astropy.units.PhysicalType`, or tuple\n",
      " |          Unit specification, can be the physical type (ie str or class).\n",
      " |          If tuple, then the first element is the unit specification\n",
      " |          and all other elements are for `numpy.ndarray` type annotations.\n",
      " |          Whether they are included depends on the python and :mod:`numpy`\n",
      " |          versions.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      `typing.Annotated`, `typing_extensions.Annotated`, `astropy.units.Unit`, or `astropy.units.PhysicalType`\n",
      " |          Return type in this preference order:\n",
      " |          * if python v3.9+ : `typing.Annotated`\n",
      " |          * if :mod:`typing_extensions` is installed : `typing_extensions.Annotated`\n",
      " |          * `astropy.units.Unit` or `astropy.units.PhysicalType`\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the unit/physical_type annotation is not Unit-like or\n",
      " |          PhysicalType-like.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Create a unit-aware Quantity type annotation\n",
      " |      \n",
      " |          >>> Quantity[Unit(\"s\")]\n",
      " |          Annotated[Quantity, Unit(\"s\")]\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      `~astropy.units.quantity_input`\n",
      " |          Use annotations for unit checks on function arguments and results.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      With Python 3.9+ or :mod:`typing_extensions`, |Quantity| types are also\n",
      " |      static-type compatible.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from astropy.units.quantity.Quantity:\n",
      " |  \n",
      " |  cgs\n",
      " |      Returns a copy of the current `Quantity` instance with CGS units. The\n",
      " |      value of the resulting object will be scaled.\n",
      " |  \n",
      " |  equivalencies\n",
      " |      A list of equivalencies that will be applied by default during\n",
      " |      unit conversions.\n",
      " |  \n",
      " |  isscalar\n",
      " |      True if the `value` of this quantity is a scalar, or False if it\n",
      " |      is an array-like object.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This is subtly different from `numpy.isscalar` in that\n",
      " |          `numpy.isscalar` returns False for a zero-dimensional array\n",
      " |          (e.g. ``np.array(1)``), while this is True for quantities,\n",
      " |          since quantities cannot represent true numpy scalars.\n",
      " |  \n",
      " |  si\n",
      " |      Returns a copy of the current `Quantity` instance with SI units. The\n",
      " |      value of the resulting object will be scaled.\n",
      " |  \n",
      " |  value\n",
      " |      The numerical value of this instance.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      to_value : Get the numerical value in a given unit.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from astropy.units.quantity.Quantity:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  flat\n",
      " |      A 1-D iterator over the Quantity array.\n",
      " |      \n",
      " |      This returns a ``QuantityIterator`` instance, which behaves the same\n",
      " |      as the `~numpy.flatiter` instance returned by `~numpy.ndarray.flat`,\n",
      " |      and is similar to, but not a subclass of, Python's built-in iterator\n",
      " |      object.\n",
      " |  \n",
      " |  info\n",
      " |      Container for meta information like name, description, format.  This is\n",
      " |      required when the object is used as a mixin column within a table, but can\n",
      " |      be used as a general way to store meta information.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from astropy.units.quantity.Quantity:\n",
      " |  \n",
      " |  __array_priority__ = 10000\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from numpy.ndarray:\n",
      " |  \n",
      " |  __abs__(self, /)\n",
      " |      abs(self)\n",
      " |  \n",
      " |  __add__(self, value, /)\n",
      " |      Return self+value.\n",
      " |  \n",
      " |  __and__(self, value, /)\n",
      " |      Return self&value.\n",
      " |  \n",
      " |  __array__(...)\n",
      " |      a.__array__([dtype], /) -> reference if type unchanged, copy otherwise.\n",
      " |      \n",
      " |      Returns either a new reference to self if dtype is not given or a new array\n",
      " |      of provided data type if dtype is different from the current dtype of the\n",
      " |      array.\n",
      " |  \n",
      " |  __array_prepare__(...)\n",
      " |      a.__array_prepare__(array[, context], /)\n",
      " |      \n",
      " |      Returns a view of `array` with the same type as self.\n",
      " |  \n",
      " |  __complex__(...)\n",
      " |  \n",
      " |  __contains__(self, key, /)\n",
      " |      Return key in self.\n",
      " |  \n",
      " |  __copy__(...)\n",
      " |      a.__copy__()\n",
      " |      \n",
      " |      Used if :func:`copy.copy` is called on an array. Returns a copy of the array.\n",
      " |      \n",
      " |      Equivalent to ``a.copy(order='K')``.\n",
      " |  \n",
      " |  __delitem__(self, key, /)\n",
      " |      Delete self[key].\n",
      " |  \n",
      " |  __divmod__(self, value, /)\n",
      " |      Return divmod(self, value).\n",
      " |  \n",
      " |  __dlpack__(...)\n",
      " |      a.__dlpack__(*, stream=None)\n",
      " |      \n",
      " |      DLPack Protocol: Part of the Array API.\n",
      " |  \n",
      " |  __dlpack_device__(...)\n",
      " |      a.__dlpack_device__()\n",
      " |      \n",
      " |      DLPack Protocol: Part of the Array API.\n",
      " |  \n",
      " |  __floordiv__(self, value, /)\n",
      " |      Return self//value.\n",
      " |  \n",
      " |  __ge__(self, value, /)\n",
      " |      Return self>=value.\n",
      " |  \n",
      " |  __gt__(self, value, /)\n",
      " |      Return self>value.\n",
      " |  \n",
      " |  __iadd__(self, value, /)\n",
      " |      Return self+=value.\n",
      " |  \n",
      " |  __iand__(self, value, /)\n",
      " |      Return self&=value.\n",
      " |  \n",
      " |  __ifloordiv__(self, value, /)\n",
      " |      Return self//=value.\n",
      " |  \n",
      " |  __imatmul__(self, value, /)\n",
      " |      Return self@=value.\n",
      " |  \n",
      " |  __imod__(self, value, /)\n",
      " |      Return self%=value.\n",
      " |  \n",
      " |  __invert__(self, /)\n",
      " |      ~self\n",
      " |  \n",
      " |  __ior__(self, value, /)\n",
      " |      Return self|=value.\n",
      " |  \n",
      " |  __ipow__(self, value, /)\n",
      " |      Return self**=value.\n",
      " |  \n",
      " |  __isub__(self, value, /)\n",
      " |      Return self-=value.\n",
      " |  \n",
      " |  __ixor__(self, value, /)\n",
      " |      Return self^=value.\n",
      " |  \n",
      " |  __le__(self, value, /)\n",
      " |      Return self<=value.\n",
      " |  \n",
      " |  __lt__(self, value, /)\n",
      " |      Return self<value.\n",
      " |  \n",
      " |  __matmul__(self, value, /)\n",
      " |      Return self@value.\n",
      " |  \n",
      " |  __mod__(self, value, /)\n",
      " |      Return self%value.\n",
      " |  \n",
      " |  __neg__(self, /)\n",
      " |      -self\n",
      " |  \n",
      " |  __or__(self, value, /)\n",
      " |      Return self|value.\n",
      " |  \n",
      " |  __pos__(self, /)\n",
      " |      +self\n",
      " |  \n",
      " |  __radd__(self, value, /)\n",
      " |      Return value+self.\n",
      " |  \n",
      " |  __rand__(self, value, /)\n",
      " |      Return value&self.\n",
      " |  \n",
      " |  __rdivmod__(self, value, /)\n",
      " |      Return divmod(value, self).\n",
      " |  \n",
      " |  __reduce_ex__(...)\n",
      " |      Helper for pickle.\n",
      " |  \n",
      " |  __rfloordiv__(self, value, /)\n",
      " |      Return value//self.\n",
      " |  \n",
      " |  __rmatmul__(self, value, /)\n",
      " |      Return value@self.\n",
      " |  \n",
      " |  __rmod__(self, value, /)\n",
      " |      Return value%self.\n",
      " |  \n",
      " |  __ror__(self, value, /)\n",
      " |      Return value|self.\n",
      " |  \n",
      " |  __rpow__(self, value, mod=None, /)\n",
      " |      Return pow(value, self, mod).\n",
      " |  \n",
      " |  __rsub__(self, value, /)\n",
      " |      Return value-self.\n",
      " |  \n",
      " |  __rxor__(self, value, /)\n",
      " |      Return value^self.\n",
      " |  \n",
      " |  __sizeof__(...)\n",
      " |      Size of object in memory, in bytes.\n",
      " |  \n",
      " |  __sub__(self, value, /)\n",
      " |      Return self-value.\n",
      " |  \n",
      " |  __xor__(self, value, /)\n",
      " |      Return self^value.\n",
      " |  \n",
      " |  argpartition(...)\n",
      " |      a.argpartition(kth, axis=-1, kind='introselect', order=None)\n",
      " |      \n",
      " |      Returns the indices that would partition this array.\n",
      " |      \n",
      " |      Refer to `numpy.argpartition` for full documentation.\n",
      " |      \n",
      " |      .. versionadded:: 1.8.0\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.argpartition : equivalent function\n",
      " |  \n",
      " |  astype(...)\n",
      " |      a.astype(dtype, order='K', casting='unsafe', subok=True, copy=True)\n",
      " |      \n",
      " |      Copy of the array, cast to a specified type.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dtype : str or dtype\n",
      " |          Typecode or data-type to which the array is cast.\n",
      " |      order : {'C', 'F', 'A', 'K'}, optional\n",
      " |          Controls the memory layout order of the result.\n",
      " |          'C' means C order, 'F' means Fortran order, 'A'\n",
      " |          means 'F' order if all the arrays are Fortran contiguous,\n",
      " |          'C' order otherwise, and 'K' means as close to the\n",
      " |          order the array elements appear in memory as possible.\n",
      " |          Default is 'K'.\n",
      " |      casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}, optional\n",
      " |          Controls what kind of data casting may occur. Defaults to 'unsafe'\n",
      " |          for backwards compatibility.\n",
      " |      \n",
      " |            * 'no' means the data types should not be cast at all.\n",
      " |            * 'equiv' means only byte-order changes are allowed.\n",
      " |            * 'safe' means only casts which can preserve values are allowed.\n",
      " |            * 'same_kind' means only safe casts or casts within a kind,\n",
      " |              like float64 to float32, are allowed.\n",
      " |            * 'unsafe' means any data conversions may be done.\n",
      " |      subok : bool, optional\n",
      " |          If True, then sub-classes will be passed-through (default), otherwise\n",
      " |          the returned array will be forced to be a base-class array.\n",
      " |      copy : bool, optional\n",
      " |          By default, astype always returns a newly allocated array. If this\n",
      " |          is set to false, and the `dtype`, `order`, and `subok`\n",
      " |          requirements are satisfied, the input array is returned instead\n",
      " |          of a copy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      arr_t : ndarray\n",
      " |          Unless `copy` is False and the other conditions for returning the input\n",
      " |          array are satisfied (see description for `copy` input parameter), `arr_t`\n",
      " |          is a new array of the same shape as the input array, with dtype, order\n",
      " |          given by `dtype`, `order`.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      .. versionchanged:: 1.17.0\n",
      " |         Casting between a simple data type and a structured one is possible only\n",
      " |         for \"unsafe\" casting.  Casting to multiple fields is allowed, but\n",
      " |         casting from multiple fields is not.\n",
      " |      \n",
      " |      .. versionchanged:: 1.9.0\n",
      " |         Casting from numeric to string types in 'safe' casting mode requires\n",
      " |         that the string dtype length is long enough to store the max\n",
      " |         integer/float value converted.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ComplexWarning\n",
      " |          When casting from complex to float or int. To avoid this,\n",
      " |          one should use ``a.real.astype(t)``.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> x = np.array([1, 2, 2.5])\n",
      " |      >>> x\n",
      " |      array([1. ,  2. ,  2.5])\n",
      " |      \n",
      " |      >>> x.astype(int)\n",
      " |      array([1, 2, 2])\n",
      " |  \n",
      " |  byteswap(...)\n",
      " |      a.byteswap(inplace=False)\n",
      " |      \n",
      " |      Swap the bytes of the array elements\n",
      " |      \n",
      " |      Toggle between low-endian and big-endian data representation by\n",
      " |      returning a byteswapped array, optionally swapped in-place.\n",
      " |      Arrays of byte-strings are not swapped. The real and imaginary\n",
      " |      parts of a complex number are swapped individually.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      inplace : bool, optional\n",
      " |          If ``True``, swap bytes in-place, default is ``False``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out : ndarray\n",
      " |          The byteswapped array. If `inplace` is ``True``, this is\n",
      " |          a view to self.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> A = np.array([1, 256, 8755], dtype=np.int16)\n",
      " |      >>> list(map(hex, A))\n",
      " |      ['0x1', '0x100', '0x2233']\n",
      " |      >>> A.byteswap(inplace=True)\n",
      " |      array([  256,     1, 13090], dtype=int16)\n",
      " |      >>> list(map(hex, A))\n",
      " |      ['0x100', '0x1', '0x3322']\n",
      " |      \n",
      " |      Arrays of byte-strings are not swapped\n",
      " |      \n",
      " |      >>> A = np.array([b'ceg', b'fac'])\n",
      " |      >>> A.byteswap()\n",
      " |      array([b'ceg', b'fac'], dtype='|S3')\n",
      " |      \n",
      " |      ``A.newbyteorder().byteswap()`` produces an array with the same values\n",
      " |        but different representation in memory\n",
      " |      \n",
      " |      >>> A = np.array([1, 2, 3])\n",
      " |      >>> A.view(np.uint8)\n",
      " |      array([1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0,\n",
      " |             0, 0], dtype=uint8)\n",
      " |      >>> A.newbyteorder().byteswap(inplace=True)\n",
      " |      array([1, 2, 3])\n",
      " |      >>> A.view(np.uint8)\n",
      " |      array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0,\n",
      " |             0, 3], dtype=uint8)\n",
      " |  \n",
      " |  clip(...)\n",
      " |      a.clip(min=None, max=None, out=None, **kwargs)\n",
      " |      \n",
      " |      Return an array whose values are limited to ``[min, max]``.\n",
      " |      One of max or min must be given.\n",
      " |      \n",
      " |      Refer to `numpy.clip` for full documentation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.clip : equivalent function\n",
      " |  \n",
      " |  compress(...)\n",
      " |      a.compress(condition, axis=None, out=None)\n",
      " |      \n",
      " |      Return selected slices of this array along given axis.\n",
      " |      \n",
      " |      Refer to `numpy.compress` for full documentation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.compress : equivalent function\n",
      " |  \n",
      " |  conj(...)\n",
      " |      a.conj()\n",
      " |      \n",
      " |      Complex-conjugate all elements.\n",
      " |      \n",
      " |      Refer to `numpy.conjugate` for full documentation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.conjugate : equivalent function\n",
      " |  \n",
      " |  conjugate(...)\n",
      " |      a.conjugate()\n",
      " |      \n",
      " |      Return the complex conjugate, element-wise.\n",
      " |      \n",
      " |      Refer to `numpy.conjugate` for full documentation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.conjugate : equivalent function\n",
      " |  \n",
      " |  cumprod(...)\n",
      " |      a.cumprod(axis=None, dtype=None, out=None)\n",
      " |      \n",
      " |      Return the cumulative product of the elements along the given axis.\n",
      " |      \n",
      " |      Refer to `numpy.cumprod` for full documentation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.cumprod : equivalent function\n",
      " |  \n",
      " |  cumsum(...)\n",
      " |      a.cumsum(axis=None, dtype=None, out=None)\n",
      " |      \n",
      " |      Return the cumulative sum of the elements along the given axis.\n",
      " |      \n",
      " |      Refer to `numpy.cumsum` for full documentation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.cumsum : equivalent function\n",
      " |  \n",
      " |  diagonal(...)\n",
      " |      a.diagonal(offset=0, axis1=0, axis2=1)\n",
      " |      \n",
      " |      Return specified diagonals. In NumPy 1.9 the returned array is a\n",
      " |      read-only view instead of a copy as in previous NumPy versions.  In\n",
      " |      a future version the read-only restriction will be removed.\n",
      " |      \n",
      " |      Refer to :func:`numpy.diagonal` for full documentation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.diagonal : equivalent function\n",
      " |  \n",
      " |  getfield(...)\n",
      " |      a.getfield(dtype, offset=0)\n",
      " |      \n",
      " |      Returns a field of the given array as a certain type.\n",
      " |      \n",
      " |      A field is a view of the array data with a given data-type. The values in\n",
      " |      the view are determined by the given type and the offset into the current\n",
      " |      array in bytes. The offset needs to be such that the view dtype fits in the\n",
      " |      array dtype; for example an array of dtype complex128 has 16-byte elements.\n",
      " |      If taking a view with a 32-bit integer (4 bytes), the offset needs to be\n",
      " |      between 0 and 12 bytes.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dtype : str or dtype\n",
      " |          The data type of the view. The dtype size of the view can not be larger\n",
      " |          than that of the array itself.\n",
      " |      offset : int\n",
      " |          Number of bytes to skip before beginning the element view.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> x = np.diag([1.+1.j]*2)\n",
      " |      >>> x[1, 1] = 2 + 4.j\n",
      " |      >>> x\n",
      " |      array([[1.+1.j,  0.+0.j],\n",
      " |             [0.+0.j,  2.+4.j]])\n",
      " |      >>> x.getfield(np.float64)\n",
      " |      array([[1.,  0.],\n",
      " |             [0.,  2.]])\n",
      " |      \n",
      " |      By choosing an offset of 8 bytes we can select the complex part of the\n",
      " |      array for our view:\n",
      " |      \n",
      " |      >>> x.getfield(np.float64, offset=8)\n",
      " |      array([[1.,  0.],\n",
      " |             [0.,  4.]])\n",
      " |  \n",
      " |  max(...)\n",
      " |      a.max(axis=None, out=None, keepdims=False, initial=<no value>, where=True)\n",
      " |      \n",
      " |      Return the maximum along a given axis.\n",
      " |      \n",
      " |      Refer to `numpy.amax` for full documentation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.amax : equivalent function\n",
      " |  \n",
      " |  min(...)\n",
      " |      a.min(axis=None, out=None, keepdims=False, initial=<no value>, where=True)\n",
      " |      \n",
      " |      Return the minimum along a given axis.\n",
      " |      \n",
      " |      Refer to `numpy.amin` for full documentation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.amin : equivalent function\n",
      " |  \n",
      " |  newbyteorder(...)\n",
      " |      arr.newbyteorder(new_order='S', /)\n",
      " |      \n",
      " |      Return the array with the same data viewed with a different byte order.\n",
      " |      \n",
      " |      Equivalent to::\n",
      " |      \n",
      " |          arr.view(arr.dtype.newbytorder(new_order))\n",
      " |      \n",
      " |      Changes are also made in all fields and sub-arrays of the array data\n",
      " |      type.\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      new_order : string, optional\n",
      " |          Byte order to force; a value from the byte order specifications\n",
      " |          below. `new_order` codes can be any of:\n",
      " |      \n",
      " |          * 'S' - swap dtype from current to opposite endian\n",
      " |          * {'<', 'little'} - little endian\n",
      " |          * {'>', 'big'} - big endian\n",
      " |          * {'=', 'native'} - native order, equivalent to `sys.byteorder`\n",
      " |          * {'|', 'I'} - ignore (no change to byte order)\n",
      " |      \n",
      " |          The default value ('S') results in swapping the current\n",
      " |          byte order.\n",
      " |      \n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      new_arr : array\n",
      " |          New array object with the dtype reflecting given change to the\n",
      " |          byte order.\n",
      " |  \n",
      " |  nonzero(...)\n",
      " |      a.nonzero()\n",
      " |      \n",
      " |      Return the indices of the elements that are non-zero.\n",
      " |      \n",
      " |      Refer to `numpy.nonzero` for full documentation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.nonzero : equivalent function\n",
      " |  \n",
      " |  partition(...)\n",
      " |      a.partition(kth, axis=-1, kind='introselect', order=None)\n",
      " |      \n",
      " |      Rearranges the elements in the array in such a way that the value of the\n",
      " |      element in kth position is in the position it would be in a sorted array.\n",
      " |      All elements smaller than the kth element are moved before this element and\n",
      " |      all equal or greater are moved behind it. The ordering of the elements in\n",
      " |      the two partitions is undefined.\n",
      " |      \n",
      " |      .. versionadded:: 1.8.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      kth : int or sequence of ints\n",
      " |          Element index to partition by. The kth element value will be in its\n",
      " |          final sorted position and all smaller elements will be moved before it\n",
      " |          and all equal or greater elements behind it.\n",
      " |          The order of all elements in the partitions is undefined.\n",
      " |          If provided with a sequence of kth it will partition all elements\n",
      " |          indexed by kth of them into their sorted position at once.\n",
      " |      \n",
      " |          .. deprecated:: 1.22.0\n",
      " |              Passing booleans as index is deprecated.\n",
      " |      axis : int, optional\n",
      " |          Axis along which to sort. Default is -1, which means sort along the\n",
      " |          last axis.\n",
      " |      kind : {'introselect'}, optional\n",
      " |          Selection algorithm. Default is 'introselect'.\n",
      " |      order : str or list of str, optional\n",
      " |          When `a` is an array with fields defined, this argument specifies\n",
      " |          which fields to compare first, second, etc. A single field can\n",
      " |          be specified as a string, and not all fields need to be specified,\n",
      " |          but unspecified fields will still be used, in the order in which\n",
      " |          they come up in the dtype, to break ties.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.partition : Return a partitioned copy of an array.\n",
      " |      argpartition : Indirect partition.\n",
      " |      sort : Full sort.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      See ``np.partition`` for notes on the different algorithms.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = np.array([3, 4, 2, 1])\n",
      " |      >>> a.partition(3)\n",
      " |      >>> a\n",
      " |      array([2, 1, 3, 4])\n",
      " |      \n",
      " |      >>> a.partition((1, 3))\n",
      " |      >>> a\n",
      " |      array([1, 2, 3, 4])\n",
      " |  \n",
      " |  prod(...)\n",
      " |      a.prod(axis=None, dtype=None, out=None, keepdims=False, initial=1, where=True)\n",
      " |      \n",
      " |      Return the product of the array elements over the given axis\n",
      " |      \n",
      " |      Refer to `numpy.prod` for full documentation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.prod : equivalent function\n",
      " |  \n",
      " |  ptp(...)\n",
      " |      a.ptp(axis=None, out=None, keepdims=False)\n",
      " |      \n",
      " |      Peak to peak (maximum - minimum) value along a given axis.\n",
      " |      \n",
      " |      Refer to `numpy.ptp` for full documentation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.ptp : equivalent function\n",
      " |  \n",
      " |  ravel(...)\n",
      " |      a.ravel([order])\n",
      " |      \n",
      " |      Return a flattened array.\n",
      " |      \n",
      " |      Refer to `numpy.ravel` for full documentation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.ravel : equivalent function\n",
      " |      \n",
      " |      ndarray.flat : a flat iterator on the array.\n",
      " |  \n",
      " |  repeat(...)\n",
      " |      a.repeat(repeats, axis=None)\n",
      " |      \n",
      " |      Repeat elements of an array.\n",
      " |      \n",
      " |      Refer to `numpy.repeat` for full documentation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.repeat : equivalent function\n",
      " |  \n",
      " |  reshape(...)\n",
      " |      a.reshape(shape, order='C')\n",
      " |      \n",
      " |      Returns an array containing the same data with a new shape.\n",
      " |      \n",
      " |      Refer to `numpy.reshape` for full documentation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.reshape : equivalent function\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Unlike the free function `numpy.reshape`, this method on `ndarray` allows\n",
      " |      the elements of the shape parameter to be passed in as separate arguments.\n",
      " |      For example, ``a.reshape(10, 11)`` is equivalent to\n",
      " |      ``a.reshape((10, 11))``.\n",
      " |  \n",
      " |  resize(...)\n",
      " |      a.resize(new_shape, refcheck=True)\n",
      " |      \n",
      " |      Change shape and size of array in-place.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      new_shape : tuple of ints, or `n` ints\n",
      " |          Shape of resized array.\n",
      " |      refcheck : bool, optional\n",
      " |          If False, reference count will not be checked. Default is True.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      None\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          If `a` does not own its own data or references or views to it exist,\n",
      " |          and the data memory must be changed.\n",
      " |          PyPy only: will always raise if the data memory must be changed, since\n",
      " |          there is no reliable way to determine if references or views to it\n",
      " |          exist.\n",
      " |      \n",
      " |      SystemError\n",
      " |          If the `order` keyword argument is specified. This behaviour is a\n",
      " |          bug in NumPy.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      resize : Return a new array with the specified shape.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This reallocates space for the data area if necessary.\n",
      " |      \n",
      " |      Only contiguous arrays (data elements consecutive in memory) can be\n",
      " |      resized.\n",
      " |      \n",
      " |      The purpose of the reference count check is to make sure you\n",
      " |      do not use this array as a buffer for another Python object and then\n",
      " |      reallocate the memory. However, reference counts can increase in\n",
      " |      other ways so if you are sure that you have not shared the memory\n",
      " |      for this array with another Python object, then you may safely set\n",
      " |      `refcheck` to False.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Shrinking an array: array is flattened (in the order that the data are\n",
      " |      stored in memory), resized, and reshaped:\n",
      " |      \n",
      " |      >>> a = np.array([[0, 1], [2, 3]], order='C')\n",
      " |      >>> a.resize((2, 1))\n",
      " |      >>> a\n",
      " |      array([[0],\n",
      " |             [1]])\n",
      " |      \n",
      " |      >>> a = np.array([[0, 1], [2, 3]], order='F')\n",
      " |      >>> a.resize((2, 1))\n",
      " |      >>> a\n",
      " |      array([[0],\n",
      " |             [2]])\n",
      " |      \n",
      " |      Enlarging an array: as above, but missing entries are filled with zeros:\n",
      " |      \n",
      " |      >>> b = np.array([[0, 1], [2, 3]])\n",
      " |      >>> b.resize(2, 3) # new_shape parameter doesn't have to be a tuple\n",
      " |      >>> b\n",
      " |      array([[0, 1, 2],\n",
      " |             [3, 0, 0]])\n",
      " |      \n",
      " |      Referencing an array prevents resizing...\n",
      " |      \n",
      " |      >>> c = a\n",
      " |      >>> a.resize((1, 1))\n",
      " |      Traceback (most recent call last):\n",
      " |      ...\n",
      " |      ValueError: cannot resize an array that references or is referenced ...\n",
      " |      \n",
      " |      Unless `refcheck` is False:\n",
      " |      \n",
      " |      >>> a.resize((1, 1), refcheck=False)\n",
      " |      >>> a\n",
      " |      array([[0]])\n",
      " |      >>> c\n",
      " |      array([[0]])\n",
      " |  \n",
      " |  setfield(...)\n",
      " |      a.setfield(val, dtype, offset=0)\n",
      " |      \n",
      " |      Put a value into a specified place in a field defined by a data-type.\n",
      " |      \n",
      " |      Place `val` into `a`'s field defined by `dtype` and beginning `offset`\n",
      " |      bytes into the field.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      val : object\n",
      " |          Value to be placed in field.\n",
      " |      dtype : dtype object\n",
      " |          Data-type of the field in which to place `val`.\n",
      " |      offset : int, optional\n",
      " |          The number of bytes into the field at which to place `val`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      None\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      getfield\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> x = np.eye(3)\n",
      " |      >>> x.getfield(np.float64)\n",
      " |      array([[1.,  0.,  0.],\n",
      " |             [0.,  1.,  0.],\n",
      " |             [0.,  0.,  1.]])\n",
      " |      >>> x.setfield(3, np.int32)\n",
      " |      >>> x.getfield(np.int32)\n",
      " |      array([[3, 3, 3],\n",
      " |             [3, 3, 3],\n",
      " |             [3, 3, 3]], dtype=int32)\n",
      " |      >>> x\n",
      " |      array([[1.0e+000, 1.5e-323, 1.5e-323],\n",
      " |             [1.5e-323, 1.0e+000, 1.5e-323],\n",
      " |             [1.5e-323, 1.5e-323, 1.0e+000]])\n",
      " |      >>> x.setfield(np.eye(3), np.int32)\n",
      " |      >>> x\n",
      " |      array([[1.,  0.,  0.],\n",
      " |             [0.,  1.,  0.],\n",
      " |             [0.,  0.,  1.]])\n",
      " |  \n",
      " |  setflags(...)\n",
      " |      a.setflags(write=None, align=None, uic=None)\n",
      " |      \n",
      " |      Set array flags WRITEABLE, ALIGNED, WRITEBACKIFCOPY,\n",
      " |      respectively.\n",
      " |      \n",
      " |      These Boolean-valued flags affect how numpy interprets the memory\n",
      " |      area used by `a` (see Notes below). The ALIGNED flag can only\n",
      " |      be set to True if the data is actually aligned according to the type.\n",
      " |      The WRITEBACKIFCOPY and flag can never be set\n",
      " |      to True. The flag WRITEABLE can only be set to True if the array owns its\n",
      " |      own memory, or the ultimate owner of the memory exposes a writeable buffer\n",
      " |      interface, or is a string. (The exception for string is made so that\n",
      " |      unpickling can be done without copying memory.)\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      write : bool, optional\n",
      " |          Describes whether or not `a` can be written to.\n",
      " |      align : bool, optional\n",
      " |          Describes whether or not `a` is aligned properly for its type.\n",
      " |      uic : bool, optional\n",
      " |          Describes whether or not `a` is a copy of another \"base\" array.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Array flags provide information about how the memory area used\n",
      " |      for the array is to be interpreted. There are 7 Boolean flags\n",
      " |      in use, only four of which can be changed by the user:\n",
      " |      WRITEBACKIFCOPY, WRITEABLE, and ALIGNED.\n",
      " |      \n",
      " |      WRITEABLE (W) the data area can be written to;\n",
      " |      \n",
      " |      ALIGNED (A) the data and strides are aligned appropriately for the hardware\n",
      " |      (as determined by the compiler);\n",
      " |      \n",
      " |      WRITEBACKIFCOPY (X) this array is a copy of some other array (referenced\n",
      " |      by .base). When the C-API function PyArray_ResolveWritebackIfCopy is\n",
      " |      called, the base array will be updated with the contents of this array.\n",
      " |      \n",
      " |      All flags can be accessed using the single (upper case) letter as well\n",
      " |      as the full name.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> y = np.array([[3, 1, 7],\n",
      " |      ...               [2, 0, 0],\n",
      " |      ...               [8, 5, 9]])\n",
      " |      >>> y\n",
      " |      array([[3, 1, 7],\n",
      " |             [2, 0, 0],\n",
      " |             [8, 5, 9]])\n",
      " |      >>> y.flags\n",
      " |        C_CONTIGUOUS : True\n",
      " |        F_CONTIGUOUS : False\n",
      " |        OWNDATA : True\n",
      " |        WRITEABLE : True\n",
      " |        ALIGNED : True\n",
      " |        WRITEBACKIFCOPY : False\n",
      " |      >>> y.setflags(write=0, align=0)\n",
      " |      >>> y.flags\n",
      " |        C_CONTIGUOUS : True\n",
      " |        F_CONTIGUOUS : False\n",
      " |        OWNDATA : True\n",
      " |        WRITEABLE : False\n",
      " |        ALIGNED : False\n",
      " |        WRITEBACKIFCOPY : False\n",
      " |      >>> y.setflags(uic=1)\n",
      " |      Traceback (most recent call last):\n",
      " |        File \"<stdin>\", line 1, in <module>\n",
      " |      ValueError: cannot set WRITEBACKIFCOPY flag to True\n",
      " |  \n",
      " |  sort(...)\n",
      " |      a.sort(axis=-1, kind=None, order=None)\n",
      " |      \n",
      " |      Sort an array in-place. Refer to `numpy.sort` for full documentation.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : int, optional\n",
      " |          Axis along which to sort. Default is -1, which means sort along the\n",
      " |          last axis.\n",
      " |      kind : {'quicksort', 'mergesort', 'heapsort', 'stable'}, optional\n",
      " |          Sorting algorithm. The default is 'quicksort'. Note that both 'stable'\n",
      " |          and 'mergesort' use timsort under the covers and, in general, the\n",
      " |          actual implementation will vary with datatype. The 'mergesort' option\n",
      " |          is retained for backwards compatibility.\n",
      " |      \n",
      " |          .. versionchanged:: 1.15.0\n",
      " |             The 'stable' option was added.\n",
      " |      \n",
      " |      order : str or list of str, optional\n",
      " |          When `a` is an array with fields defined, this argument specifies\n",
      " |          which fields to compare first, second, etc.  A single field can\n",
      " |          be specified as a string, and not all fields need be specified,\n",
      " |          but unspecified fields will still be used, in the order in which\n",
      " |          they come up in the dtype, to break ties.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.sort : Return a sorted copy of an array.\n",
      " |      numpy.argsort : Indirect sort.\n",
      " |      numpy.lexsort : Indirect stable sort on multiple keys.\n",
      " |      numpy.searchsorted : Find elements in sorted array.\n",
      " |      numpy.partition: Partial sort.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      See `numpy.sort` for notes on the different sorting algorithms.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = np.array([[1,4], [3,1]])\n",
      " |      >>> a.sort(axis=1)\n",
      " |      >>> a\n",
      " |      array([[1, 4],\n",
      " |             [1, 3]])\n",
      " |      >>> a.sort(axis=0)\n",
      " |      >>> a\n",
      " |      array([[1, 3],\n",
      " |             [1, 4]])\n",
      " |      \n",
      " |      Use the `order` keyword to specify a field to use when sorting a\n",
      " |      structured array:\n",
      " |      \n",
      " |      >>> a = np.array([('a', 2), ('c', 1)], dtype=[('x', 'S1'), ('y', int)])\n",
      " |      >>> a.sort(order='y')\n",
      " |      >>> a\n",
      " |      array([(b'c', 1), (b'a', 2)],\n",
      " |            dtype=[('x', 'S1'), ('y', '<i8')])\n",
      " |  \n",
      " |  squeeze(...)\n",
      " |      a.squeeze(axis=None)\n",
      " |      \n",
      " |      Remove axes of length one from `a`.\n",
      " |      \n",
      " |      Refer to `numpy.squeeze` for full documentation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.squeeze : equivalent function\n",
      " |  \n",
      " |  sum(...)\n",
      " |      a.sum(axis=None, dtype=None, out=None, keepdims=False, initial=0, where=True)\n",
      " |      \n",
      " |      Return the sum of the array elements over the given axis.\n",
      " |      \n",
      " |      Refer to `numpy.sum` for full documentation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.sum : equivalent function\n",
      " |  \n",
      " |  swapaxes(...)\n",
      " |      a.swapaxes(axis1, axis2)\n",
      " |      \n",
      " |      Return a view of the array with `axis1` and `axis2` interchanged.\n",
      " |      \n",
      " |      Refer to `numpy.swapaxes` for full documentation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.swapaxes : equivalent function\n",
      " |  \n",
      " |  transpose(...)\n",
      " |      a.transpose(*axes)\n",
      " |      \n",
      " |      Returns a view of the array with axes transposed.\n",
      " |      \n",
      " |      For a 1-D array this has no effect, as a transposed vector is simply the\n",
      " |      same vector. To convert a 1-D array into a 2D column vector, an additional\n",
      " |      dimension must be added. `np.atleast2d(a).T` achieves this, as does\n",
      " |      `a[:, np.newaxis]`.\n",
      " |      For a 2-D array, this is a standard matrix transpose.\n",
      " |      For an n-D array, if axes are given, their order indicates how the\n",
      " |      axes are permuted (see Examples). If axes are not provided and\n",
      " |      ``a.shape = (i[0], i[1], ... i[n-2], i[n-1])``, then\n",
      " |      ``a.transpose().shape = (i[n-1], i[n-2], ... i[1], i[0])``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axes : None, tuple of ints, or `n` ints\n",
      " |      \n",
      " |       * None or no argument: reverses the order of the axes.\n",
      " |      \n",
      " |       * tuple of ints: `i` in the `j`-th place in the tuple means `a`'s\n",
      " |         `i`-th axis becomes `a.transpose()`'s `j`-th axis.\n",
      " |      \n",
      " |       * `n` ints: same as an n-tuple of the same ints (this form is\n",
      " |         intended simply as a \"convenience\" alternative to the tuple form)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out : ndarray\n",
      " |          View of `a`, with axes suitably permuted.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      transpose : Equivalent function\n",
      " |      ndarray.T : Array property returning the array transposed.\n",
      " |      ndarray.reshape : Give a new shape to an array without changing its data.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = np.array([[1, 2], [3, 4]])\n",
      " |      >>> a\n",
      " |      array([[1, 2],\n",
      " |             [3, 4]])\n",
      " |      >>> a.transpose()\n",
      " |      array([[1, 3],\n",
      " |             [2, 4]])\n",
      " |      >>> a.transpose((1, 0))\n",
      " |      array([[1, 3],\n",
      " |             [2, 4]])\n",
      " |      >>> a.transpose(1, 0)\n",
      " |      array([[1, 3],\n",
      " |             [2, 4]])\n",
      " |  \n",
      " |  view(...)\n",
      " |      a.view([dtype][, type])\n",
      " |      \n",
      " |      New view of array with the same data.\n",
      " |      \n",
      " |      .. note::\n",
      " |          Passing None for ``dtype`` is different from omitting the parameter,\n",
      " |          since the former invokes ``dtype(None)`` which is an alias for\n",
      " |          ``dtype('float_')``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dtype : data-type or ndarray sub-class, optional\n",
      " |          Data-type descriptor of the returned view, e.g., float32 or int16.\n",
      " |          Omitting it results in the view having the same data-type as `a`.\n",
      " |          This argument can also be specified as an ndarray sub-class, which\n",
      " |          then specifies the type of the returned object (this is equivalent to\n",
      " |          setting the ``type`` parameter).\n",
      " |      type : Python type, optional\n",
      " |          Type of the returned view, e.g., ndarray or matrix.  Again, omission\n",
      " |          of the parameter results in type preservation.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      ``a.view()`` is used two different ways:\n",
      " |      \n",
      " |      ``a.view(some_dtype)`` or ``a.view(dtype=some_dtype)`` constructs a view\n",
      " |      of the array's memory with a different data-type.  This can cause a\n",
      " |      reinterpretation of the bytes of memory.\n",
      " |      \n",
      " |      ``a.view(ndarray_subclass)`` or ``a.view(type=ndarray_subclass)`` just\n",
      " |      returns an instance of `ndarray_subclass` that looks at the same array\n",
      " |      (same shape, dtype, etc.)  This does not cause a reinterpretation of the\n",
      " |      memory.\n",
      " |      \n",
      " |      For ``a.view(some_dtype)``, if ``some_dtype`` has a different number of\n",
      " |      bytes per entry than the previous dtype (for example, converting a regular\n",
      " |      array to a structured array), then the last axis of ``a`` must be\n",
      " |      contiguous. This axis will be resized in the result.\n",
      " |      \n",
      " |      .. versionchanged:: 1.23.0\n",
      " |         Only the last axis needs to be contiguous. Previously, the entire array\n",
      " |         had to be C-contiguous.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> x = np.array([(1, 2)], dtype=[('a', np.int8), ('b', np.int8)])\n",
      " |      \n",
      " |      Viewing array data using a different type and dtype:\n",
      " |      \n",
      " |      >>> y = x.view(dtype=np.int16, type=np.matrix)\n",
      " |      >>> y\n",
      " |      matrix([[513]], dtype=int16)\n",
      " |      >>> print(type(y))\n",
      " |      <class 'numpy.matrix'>\n",
      " |      \n",
      " |      Creating a view on a structured array so it can be used in calculations\n",
      " |      \n",
      " |      >>> x = np.array([(1, 2),(3,4)], dtype=[('a', np.int8), ('b', np.int8)])\n",
      " |      >>> xv = x.view(dtype=np.int8).reshape(-1,2)\n",
      " |      >>> xv\n",
      " |      array([[1, 2],\n",
      " |             [3, 4]], dtype=int8)\n",
      " |      >>> xv.mean(0)\n",
      " |      array([2.,  3.])\n",
      " |      \n",
      " |      Making changes to the view changes the underlying array\n",
      " |      \n",
      " |      >>> xv[0,1] = 20\n",
      " |      >>> x\n",
      " |      array([(1, 20), (3,  4)], dtype=[('a', 'i1'), ('b', 'i1')])\n",
      " |      \n",
      " |      Using a view to convert an array to a recarray:\n",
      " |      \n",
      " |      >>> z = x.view(np.recarray)\n",
      " |      >>> z.a\n",
      " |      array([1, 3], dtype=int8)\n",
      " |      \n",
      " |      Views share data:\n",
      " |      \n",
      " |      >>> x[0] = (9, 10)\n",
      " |      >>> z[0]\n",
      " |      (9, 10)\n",
      " |      \n",
      " |      Views that change the dtype size (bytes per entry) should normally be\n",
      " |      avoided on arrays defined by slices, transposes, fortran-ordering, etc.:\n",
      " |      \n",
      " |      >>> x = np.array([[1, 2, 3], [4, 5, 6]], dtype=np.int16)\n",
      " |      >>> y = x[:, ::2]\n",
      " |      >>> y\n",
      " |      array([[1, 3],\n",
      " |             [4, 6]], dtype=int16)\n",
      " |      >>> y.view(dtype=[('width', np.int16), ('length', np.int16)])\n",
      " |      Traceback (most recent call last):\n",
      " |          ...\n",
      " |      ValueError: To change to a dtype of a different size, the last axis must be contiguous\n",
      " |      >>> z = y.copy()\n",
      " |      >>> z.view(dtype=[('width', np.int16), ('length', np.int16)])\n",
      " |      array([[(1, 3)],\n",
      " |             [(4, 6)]], dtype=[('width', '<i2'), ('length', '<i2')])\n",
      " |      \n",
      " |      However, views that change dtype are totally fine for arrays with a\n",
      " |      contiguous last axis, even if the rest of the axes are not C-contiguous:\n",
      " |      \n",
      " |      >>> x = np.arange(2 * 3 * 4, dtype=np.int8).reshape(2, 3, 4)\n",
      " |      >>> x.transpose(1, 0, 2).view(np.int16)\n",
      " |      array([[[ 256,  770],\n",
      " |              [3340, 3854]],\n",
      " |      <BLANKLINE>\n",
      " |             [[1284, 1798],\n",
      " |              [4368, 4882]],\n",
      " |      <BLANKLINE>\n",
      " |             [[2312, 2826],\n",
      " |              [5396, 5910]]], dtype=int16)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from numpy.ndarray:\n",
      " |  \n",
      " |  T\n",
      " |      The transposed array.\n",
      " |      \n",
      " |      Same as ``self.transpose()``.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> x = np.array([[1.,2.],[3.,4.]])\n",
      " |      >>> x\n",
      " |      array([[ 1.,  2.],\n",
      " |             [ 3.,  4.]])\n",
      " |      >>> x.T\n",
      " |      array([[ 1.,  3.],\n",
      " |             [ 2.,  4.]])\n",
      " |      >>> x = np.array([1.,2.,3.,4.])\n",
      " |      >>> x\n",
      " |      array([ 1.,  2.,  3.,  4.])\n",
      " |      >>> x.T\n",
      " |      array([ 1.,  2.,  3.,  4.])\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      transpose\n",
      " |  \n",
      " |  __array_interface__\n",
      " |      Array protocol: Python side.\n",
      " |  \n",
      " |  __array_struct__\n",
      " |      Array protocol: C-struct side.\n",
      " |  \n",
      " |  base\n",
      " |      Base object if memory is from some other object.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      The base of an array that owns its memory is None:\n",
      " |      \n",
      " |      >>> x = np.array([1,2,3,4])\n",
      " |      >>> x.base is None\n",
      " |      True\n",
      " |      \n",
      " |      Slicing creates a view, whose memory is shared with x:\n",
      " |      \n",
      " |      >>> y = x[2:]\n",
      " |      >>> y.base is x\n",
      " |      True\n",
      " |  \n",
      " |  ctypes\n",
      " |      An object to simplify the interaction of the array with the ctypes\n",
      " |      module.\n",
      " |      \n",
      " |      This attribute creates an object that makes it easier to use arrays\n",
      " |      when calling shared libraries with the ctypes module. The returned\n",
      " |      object has, among others, data, shape, and strides attributes (see\n",
      " |      Notes below) which themselves return ctypes objects that can be used\n",
      " |      as arguments to a shared library.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      None\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      c : Python object\n",
      " |          Possessing attributes data, shape, strides, etc.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.ctypeslib\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Below are the public attributes of this object which were documented\n",
      " |      in \"Guide to NumPy\" (we have omitted undocumented public attributes,\n",
      " |      as well as documented private attributes):\n",
      " |      \n",
      " |      .. autoattribute:: numpy.core._internal._ctypes.data\n",
      " |          :noindex:\n",
      " |      \n",
      " |      .. autoattribute:: numpy.core._internal._ctypes.shape\n",
      " |          :noindex:\n",
      " |      \n",
      " |      .. autoattribute:: numpy.core._internal._ctypes.strides\n",
      " |          :noindex:\n",
      " |      \n",
      " |      .. automethod:: numpy.core._internal._ctypes.data_as\n",
      " |          :noindex:\n",
      " |      \n",
      " |      .. automethod:: numpy.core._internal._ctypes.shape_as\n",
      " |          :noindex:\n",
      " |      \n",
      " |      .. automethod:: numpy.core._internal._ctypes.strides_as\n",
      " |          :noindex:\n",
      " |      \n",
      " |      If the ctypes module is not available, then the ctypes attribute\n",
      " |      of array objects still returns something useful, but ctypes objects\n",
      " |      are not returned and errors may be raised instead. In particular,\n",
      " |      the object will still have the ``as_parameter`` attribute which will\n",
      " |      return an integer equal to the data attribute.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import ctypes\n",
      " |      >>> x = np.array([[0, 1], [2, 3]], dtype=np.int32)\n",
      " |      >>> x\n",
      " |      array([[0, 1],\n",
      " |             [2, 3]], dtype=int32)\n",
      " |      >>> x.ctypes.data\n",
      " |      31962608 # may vary\n",
      " |      >>> x.ctypes.data_as(ctypes.POINTER(ctypes.c_uint32))\n",
      " |      <__main__.LP_c_uint object at 0x7ff2fc1fc200> # may vary\n",
      " |      >>> x.ctypes.data_as(ctypes.POINTER(ctypes.c_uint32)).contents\n",
      " |      c_uint(0)\n",
      " |      >>> x.ctypes.data_as(ctypes.POINTER(ctypes.c_uint64)).contents\n",
      " |      c_ulong(4294967296)\n",
      " |      >>> x.ctypes.shape\n",
      " |      <numpy.core._internal.c_long_Array_2 object at 0x7ff2fc1fce60> # may vary\n",
      " |      >>> x.ctypes.strides\n",
      " |      <numpy.core._internal.c_long_Array_2 object at 0x7ff2fc1ff320> # may vary\n",
      " |  \n",
      " |  data\n",
      " |      Python buffer object pointing to the start of the array's data.\n",
      " |  \n",
      " |  dtype\n",
      " |      Data-type of the array's elements.\n",
      " |      \n",
      " |      .. warning::\n",
      " |      \n",
      " |          Setting ``arr.dtype`` is discouraged and may be deprecated in the\n",
      " |          future.  Setting will replace the ``dtype`` without modifying the\n",
      " |          memory (see also `ndarray.view` and `ndarray.astype`).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      None\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      d : numpy dtype object\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      ndarray.astype : Cast the values contained in the array to a new data-type.\n",
      " |      ndarray.view : Create a view of the same data but a different data-type.\n",
      " |      numpy.dtype\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> x\n",
      " |      array([[0, 1],\n",
      " |             [2, 3]])\n",
      " |      >>> x.dtype\n",
      " |      dtype('int32')\n",
      " |      >>> type(x.dtype)\n",
      " |      <type 'numpy.dtype'>\n",
      " |  \n",
      " |  flags\n",
      " |      Information about the memory layout of the array.\n",
      " |      \n",
      " |      Attributes\n",
      " |      ----------\n",
      " |      C_CONTIGUOUS (C)\n",
      " |          The data is in a single, C-style contiguous segment.\n",
      " |      F_CONTIGUOUS (F)\n",
      " |          The data is in a single, Fortran-style contiguous segment.\n",
      " |      OWNDATA (O)\n",
      " |          The array owns the memory it uses or borrows it from another object.\n",
      " |      WRITEABLE (W)\n",
      " |          The data area can be written to.  Setting this to False locks\n",
      " |          the data, making it read-only.  A view (slice, etc.) inherits WRITEABLE\n",
      " |          from its base array at creation time, but a view of a writeable\n",
      " |          array may be subsequently locked while the base array remains writeable.\n",
      " |          (The opposite is not true, in that a view of a locked array may not\n",
      " |          be made writeable.  However, currently, locking a base object does not\n",
      " |          lock any views that already reference it, so under that circumstance it\n",
      " |          is possible to alter the contents of a locked array via a previously\n",
      " |          created writeable view onto it.)  Attempting to change a non-writeable\n",
      " |          array raises a RuntimeError exception.\n",
      " |      ALIGNED (A)\n",
      " |          The data and all elements are aligned appropriately for the hardware.\n",
      " |      WRITEBACKIFCOPY (X)\n",
      " |          This array is a copy of some other array. The C-API function\n",
      " |          PyArray_ResolveWritebackIfCopy must be called before deallocating\n",
      " |          to the base array will be updated with the contents of this array.\n",
      " |      FNC\n",
      " |          F_CONTIGUOUS and not C_CONTIGUOUS.\n",
      " |      FORC\n",
      " |          F_CONTIGUOUS or C_CONTIGUOUS (one-segment test).\n",
      " |      BEHAVED (B)\n",
      " |          ALIGNED and WRITEABLE.\n",
      " |      CARRAY (CA)\n",
      " |          BEHAVED and C_CONTIGUOUS.\n",
      " |      FARRAY (FA)\n",
      " |          BEHAVED and F_CONTIGUOUS and not C_CONTIGUOUS.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The `flags` object can be accessed dictionary-like (as in ``a.flags['WRITEABLE']``),\n",
      " |      or by using lowercased attribute names (as in ``a.flags.writeable``). Short flag\n",
      " |      names are only supported in dictionary access.\n",
      " |      \n",
      " |      Only the WRITEBACKIFCOPY, WRITEABLE, and ALIGNED flags can be\n",
      " |      changed by the user, via direct assignment to the attribute or dictionary\n",
      " |      entry, or by calling `ndarray.setflags`.\n",
      " |      \n",
      " |      The array flags cannot be set arbitrarily:\n",
      " |      \n",
      " |      - WRITEBACKIFCOPY can only be set ``False``.\n",
      " |      - ALIGNED can only be set ``True`` if the data is truly aligned.\n",
      " |      - WRITEABLE can only be set ``True`` if the array owns its own memory\n",
      " |        or the ultimate owner of the memory exposes a writeable buffer\n",
      " |        interface or is a string.\n",
      " |      \n",
      " |      Arrays can be both C-style and Fortran-style contiguous simultaneously.\n",
      " |      This is clear for 1-dimensional arrays, but can also be true for higher\n",
      " |      dimensional arrays.\n",
      " |      \n",
      " |      Even for contiguous arrays a stride for a given dimension\n",
      " |      ``arr.strides[dim]`` may be *arbitrary* if ``arr.shape[dim] == 1``\n",
      " |      or the array has no elements.\n",
      " |      It does *not* generally hold that ``self.strides[-1] == self.itemsize``\n",
      " |      for C-style contiguous arrays or ``self.strides[0] == self.itemsize`` for\n",
      " |      Fortran-style contiguous arrays is true.\n",
      " |  \n",
      " |  imag\n",
      " |      The imaginary part of the array.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> x = np.sqrt([1+0j, 0+1j])\n",
      " |      >>> x.imag\n",
      " |      array([ 0.        ,  0.70710678])\n",
      " |      >>> x.imag.dtype\n",
      " |      dtype('float64')\n",
      " |  \n",
      " |  itemsize\n",
      " |      Length of one array element in bytes.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> x = np.array([1,2,3], dtype=np.float64)\n",
      " |      >>> x.itemsize\n",
      " |      8\n",
      " |      >>> x = np.array([1,2,3], dtype=np.complex128)\n",
      " |      >>> x.itemsize\n",
      " |      16\n",
      " |  \n",
      " |  nbytes\n",
      " |      Total bytes consumed by the elements of the array.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Does not include memory consumed by non-element attributes of the\n",
      " |      array object.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> x = np.zeros((3,5,2), dtype=np.complex128)\n",
      " |      >>> x.nbytes\n",
      " |      480\n",
      " |      >>> np.prod(x.shape) * x.itemsize\n",
      " |      480\n",
      " |  \n",
      " |  ndim\n",
      " |      Number of array dimensions.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> x = np.array([1, 2, 3])\n",
      " |      >>> x.ndim\n",
      " |      1\n",
      " |      >>> y = np.zeros((2, 3, 4))\n",
      " |      >>> y.ndim\n",
      " |      3\n",
      " |  \n",
      " |  real\n",
      " |      The real part of the array.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> x = np.sqrt([1+0j, 0+1j])\n",
      " |      >>> x.real\n",
      " |      array([ 1.        ,  0.70710678])\n",
      " |      >>> x.real.dtype\n",
      " |      dtype('float64')\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.real : equivalent function\n",
      " |  \n",
      " |  shape\n",
      " |      Tuple of array dimensions.\n",
      " |      \n",
      " |      The shape property is usually used to get the current shape of an array,\n",
      " |      but may also be used to reshape the array in-place by assigning a tuple of\n",
      " |      array dimensions to it.  As with `numpy.reshape`, one of the new shape\n",
      " |      dimensions can be -1, in which case its value is inferred from the size of\n",
      " |      the array and the remaining dimensions. Reshaping an array in-place will\n",
      " |      fail if a copy is required.\n",
      " |      \n",
      " |      .. warning::\n",
      " |      \n",
      " |          Setting ``arr.shape`` is discouraged and may be deprecated in the\n",
      " |          future.  Using `ndarray.reshape` is the preferred approach.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> x = np.array([1, 2, 3, 4])\n",
      " |      >>> x.shape\n",
      " |      (4,)\n",
      " |      >>> y = np.zeros((2, 3, 4))\n",
      " |      >>> y.shape\n",
      " |      (2, 3, 4)\n",
      " |      >>> y.shape = (3, 8)\n",
      " |      >>> y\n",
      " |      array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      " |             [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      " |             [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      " |      >>> y.shape = (3, 6)\n",
      " |      Traceback (most recent call last):\n",
      " |        File \"<stdin>\", line 1, in <module>\n",
      " |      ValueError: total size of new array must be unchanged\n",
      " |      >>> np.zeros((4,2))[::2].shape = (-1,)\n",
      " |      Traceback (most recent call last):\n",
      " |        File \"<stdin>\", line 1, in <module>\n",
      " |      AttributeError: Incompatible shape for in-place modification. Use\n",
      " |      `.reshape()` to make a copy with the desired shape.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.shape : Equivalent getter function.\n",
      " |      numpy.reshape : Function similar to setting ``shape``.\n",
      " |      ndarray.reshape : Method similar to setting ``shape``.\n",
      " |  \n",
      " |  size\n",
      " |      Number of elements in the array.\n",
      " |      \n",
      " |      Equal to ``np.prod(a.shape)``, i.e., the product of the array's\n",
      " |      dimensions.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      `a.size` returns a standard arbitrary precision Python integer. This\n",
      " |      may not be the case with other methods of obtaining the same value\n",
      " |      (like the suggested ``np.prod(a.shape)``, which returns an instance\n",
      " |      of ``np.int_``), and may be relevant if the value is used further in\n",
      " |      calculations that may overflow a fixed size integer type.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> x = np.zeros((3, 5, 2), dtype=np.complex128)\n",
      " |      >>> x.size\n",
      " |      30\n",
      " |      >>> np.prod(x.shape)\n",
      " |      30\n",
      " |  \n",
      " |  strides\n",
      " |      Tuple of bytes to step in each dimension when traversing an array.\n",
      " |      \n",
      " |      The byte offset of element ``(i[0], i[1], ..., i[n])`` in an array `a`\n",
      " |      is::\n",
      " |      \n",
      " |          offset = sum(np.array(i) * a.strides)\n",
      " |      \n",
      " |      A more detailed explanation of strides can be found in the\n",
      " |      \"ndarray.rst\" file in the NumPy reference guide.\n",
      " |      \n",
      " |      .. warning::\n",
      " |      \n",
      " |          Setting ``arr.strides`` is discouraged and may be deprecated in the\n",
      " |          future.  `numpy.lib.stride_tricks.as_strided` should be preferred\n",
      " |          to create a new view of the same data in a safer way.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Imagine an array of 32-bit integers (each 4 bytes)::\n",
      " |      \n",
      " |        x = np.array([[0, 1, 2, 3, 4],\n",
      " |                      [5, 6, 7, 8, 9]], dtype=np.int32)\n",
      " |      \n",
      " |      This array is stored in memory as 40 bytes, one after the other\n",
      " |      (known as a contiguous block of memory).  The strides of an array tell\n",
      " |      us how many bytes we have to skip in memory to move to the next position\n",
      " |      along a certain axis.  For example, we have to skip 4 bytes (1 value) to\n",
      " |      move to the next column, but 20 bytes (5 values) to get to the same\n",
      " |      position in the next row.  As such, the strides for the array `x` will be\n",
      " |      ``(20, 4)``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.lib.stride_tricks.as_strided\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> y = np.reshape(np.arange(2*3*4), (2,3,4))\n",
      " |      >>> y\n",
      " |      array([[[ 0,  1,  2,  3],\n",
      " |              [ 4,  5,  6,  7],\n",
      " |              [ 8,  9, 10, 11]],\n",
      " |             [[12, 13, 14, 15],\n",
      " |              [16, 17, 18, 19],\n",
      " |              [20, 21, 22, 23]]])\n",
      " |      >>> y.strides\n",
      " |      (48, 16, 4)\n",
      " |      >>> y[1,1,1]\n",
      " |      17\n",
      " |      >>> offset=sum(y.strides * np.array((1,1,1)))\n",
      " |      >>> offset/y.itemsize\n",
      " |      17\n",
      " |      \n",
      " |      >>> x = np.reshape(np.arange(5*6*7*8), (5,6,7,8)).transpose(2,3,1,0)\n",
      " |      >>> x.strides\n",
      " |      (32, 4, 224, 1344)\n",
      " |      >>> i = np.array([3,5,2,2])\n",
      " |      >>> offset = sum(i * x.strides)\n",
      " |      >>> x[3,5,2,2]\n",
      " |      813\n",
      " |      >>> offset / x.itemsize\n",
      " |      813\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(det_strain['L1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "invisible-attitude",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$0.00024414062 \\; \\mathrm{s}$"
      ],
      "text/plain": [
       "<Quantity 0.00024414 s>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "det_strain['V1'].dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "closing-accused",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- storing the data in .hdf file --\n",
    "\n",
    "data = {}\n",
    "\n",
    "for ifo in ifos:\n",
    "    \n",
    "    data[ifo] = TimeSeries(np.array(det_strain[ifo]), delta_t = 0.00024414062, epoch=start_time)\n",
    "    data[ifo].save('GW170817_post_merger_only_noise_1187009082-5000.hdf', group='strain_{}'.format(ifo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatty-domestic",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pycbc_env",
   "language": "python",
   "name": "pycbc_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
